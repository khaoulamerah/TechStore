{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da295553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üè™ TECHSTORE - ETL PIPELINE\n",
      "======================================================================\n",
      "üìÅ Project Root: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\n",
      "üìÖ Execution: 2026-01-27 19:54:31\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìä EXTRACTION MYSQL (ERP)\n",
      "======================================================================\n",
      "‚ùå Erreur extraction MySQL: No module named 'mysql'\n",
      "   Assurez-vous que scripts/extract_mysql.py existe\n",
      "\n",
      "======================================================================\n",
      "üï∑Ô∏è WEB SCRAPING - PRIX CONCURRENTS\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 19:54:31,886 - INFO - ============================================================\n",
      "2026-01-27 19:54:31,886 - INFO - Starting web scraping process\n",
      "2026-01-27 19:54:31,886 - INFO - ============================================================\n",
      "2026-01-27 19:54:31,890 - INFO - Fetching page: https://boughida.com/competitor/\n",
      "2026-01-27 19:54:32,157 - INFO - Page successfully retrieved\n",
      "2026-01-27 19:54:32,157 - INFO - Found additional pages: 2\n",
      "2026-01-27 19:54:32,162 - INFO - \n",
      "Page 1/3: https://boughida.com/competitor/\n",
      "2026-01-27 19:54:32,163 - INFO - ------------------------------------------------------------\n",
      "2026-01-27 19:54:32,164 - INFO - Fetching page: https://boughida.com/competitor/\n",
      "2026-01-27 19:54:32,403 - INFO - Page successfully retrieved\n",
      "2026-01-27 19:54:32,413 - INFO - Found 13 potential product containers\n",
      "2026-01-27 19:54:32,415 - INFO - Extracted: Samsung S23 Ultra: 174800.0 DZD\n",
      "2026-01-27 19:54:32,415 - INFO - Extracted: HP LaserJet Pro: 46000.0 DZD\n",
      "2026-01-27 19:54:32,419 - INFO - Extracted: Dell 24 Monitor: 24200.0 DZD\n",
      "2026-01-27 19:54:32,422 - INFO - Extracted: Canon i-Sensys: 39000.0 DZD\n",
      "2026-01-27 19:54:32,422 - INFO - Extracted: Epson EcoTank: 27700.0 DZD\n",
      "2026-01-27 19:54:32,422 - INFO - Extracted: Nikon D3500: 69200.0 DZD\n",
      "2026-01-27 19:54:32,425 - INFO - Extracted: Xiaomi Redmi Note 12: 36800.0 DZD\n",
      "2026-01-27 19:54:32,427 - INFO - Extracted: HP Pavilion Desktop: 83000.0 DZD\n",
      "2026-01-27 19:54:32,427 - INFO - Extracted: Redmi Buds 4: 5300.0 DZD\n",
      "2026-01-27 19:54:32,427 - INFO - Extracted: DJI Mini 3: 126900.0 DZD\n",
      "2026-01-27 19:54:32,430 - INFO - Extracted: Sony SRS-XB13: 11100.0 DZD\n",
      "2026-01-27 19:54:32,433 - INFO - Extracted: ASUS ROG STRIX: 290600.0 DZD\n",
      "2026-01-27 19:54:32,434 - INFO - Extracted: LG UltraGear: 41700.0 DZD\n",
      "2026-01-27 19:54:34,436 - INFO - \n",
      "Page 2/3: https://boughida.com/competitor/competitor_page_2.html\n",
      "2026-01-27 19:54:34,436 - INFO - ------------------------------------------------------------\n",
      "2026-01-27 19:54:34,436 - INFO - Fetching page: https://boughida.com/competitor/competitor_page_2.html\n",
      "2026-01-27 19:54:34,669 - INFO - Page successfully retrieved\n",
      "2026-01-27 19:54:34,671 - INFO - Found 13 potential product containers\n",
      "2026-01-27 19:54:34,674 - INFO - Extracted: IPHONE CABLE: 3200.0 DZD\n",
      "2026-01-27 19:54:34,675 - INFO - Extracted: Lenovo ThinkPad: 94600.0 DZD\n",
      "2026-01-27 19:54:34,675 - INFO - Extracted: AirPods Pro: 47400.0 DZD\n",
      "2026-01-27 19:54:34,678 - INFO - Extracted: Phone Case Silicon: 1800.0 DZD\n",
      "2026-01-27 19:54:34,680 - INFO - Extracted: Sony WH-1000XM5: 65400.0 DZD\n",
      "2026-01-27 19:54:34,682 - INFO - Extracted: iPhone 13: 136900.0 DZD\n",
      "2026-01-27 19:54:34,682 - INFO - Extracted: Canon 445 Black: 2600.0 DZD\n",
      "2026-01-27 19:54:34,684 - INFO - Extracted: DJI Mavic 3: 350400.0 DZD\n",
      "2026-01-27 19:54:34,685 - INFO - Extracted: JBL Flip 6: 23500.0 DZD\n",
      "2026-01-27 19:54:34,685 - INFO - Extracted: HP VICTUS 15: 119700.0 DZD\n",
      "2026-01-27 19:54:34,685 - INFO - Extracted: HP 650 Black: 2900.0 DZD\n",
      "2026-01-27 19:54:34,690 - INFO - Extracted: Oppo Reno 8: 60200.0 DZD\n",
      "2026-01-27 19:54:34,691 - INFO - Extracted: SAMSUNG CHARGER 25W: 4200.0 DZD\n",
      "2026-01-27 19:54:36,692 - INFO - \n",
      "Page 3/3: https://boughida.com/competitor/competitor_page_3.html\n",
      "2026-01-27 19:54:36,693 - INFO - ------------------------------------------------------------\n",
      "2026-01-27 19:54:36,693 - INFO - Fetching page: https://boughida.com/competitor/competitor_page_3.html\n",
      "2026-01-27 19:54:36,945 - INFO - Page successfully retrieved\n",
      "2026-01-27 19:54:36,950 - INFO - Found 12 potential product containers\n",
      "2026-01-27 19:54:36,950 - INFO - Extracted: MacBook Air M2: 190500.0 DZD\n",
      "2026-01-27 19:54:36,955 - INFO - Extracted: Canon Pixma: 11600.0 DZD\n",
      "2026-01-27 19:54:36,992 - INFO - Extracted: Canon EOS 4000D: 60200.0 DZD\n",
      "2026-01-27 19:54:36,994 - INFO - Extracted: JBL Tune 510BT: 11200.0 DZD\n",
      "2026-01-27 19:54:36,995 - INFO - Extracted: Screen Protector: 930.0 DZD\n",
      "2026-01-27 19:54:36,997 - INFO - Extracted: Custom Gaming PC: 300000.0 DZD\n",
      "2026-01-27 19:54:36,998 - INFO - Extracted: Samsung Odyssey G5: 46700.0 DZD\n",
      "2026-01-27 19:54:37,000 - INFO - Extracted: Realme GT3: 71700.0 DZD\n",
      "2026-01-27 19:54:37,001 - INFO - Extracted: iPhone 14 Pro: 212700.0 DZD\n",
      "2026-01-27 19:54:37,002 - INFO - Extracted: IPHONE 15 PRO MAX: 281500.0 DZD\n",
      "2026-01-27 19:54:37,004 - INFO - Extracted: Dell XPS 13 5G: 242700.0 DZD\n",
      "2026-01-27 19:54:37,005 - INFO - Extracted: Dell OptiPlex: 64400.0 DZD\n",
      "2026-01-27 19:54:37,005 - INFO - ============================================================\n",
      "2026-01-27 19:54:37,005 - INFO - Scraping completed: 38 total products\n",
      "2026-01-27 19:54:37,009 - INFO - ============================================================\n",
      "2026-01-27 19:54:37,018 - INFO - \n",
      "Data saved to: data/extracted/competitor_prices.csv\n",
      "2026-01-27 19:54:37,019 - INFO - Statistics:\n",
      "2026-01-27 19:54:37,020 - INFO -   Total products: 38\n",
      "2026-01-27 19:54:37,020 - INFO -   Average price: 89032.37 DZD\n",
      "2026-01-27 19:54:37,020 - INFO -   Price range: 930 - 350400 DZD\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15416\\393743026.py\", line 220, in <module>\n",
      "    import transform_data\n",
      "  File \"c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\scripts\\transform_data.py\", line 3, in <module>\n",
      "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
      "ModuleNotFoundError: No module named 'vaderSentiment'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ 38 prix concurrents extraits\n",
      "üíæ Fichier: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\Data\\extracted\\competitor_prices.csv\n",
      "\n",
      "üìä Aper√ßu:\n",
      "  Competitor_Product_Name  Competitor_Price Product_Reference Currency\n",
      "0       Samsung S23 Ultra          174800.0       Ref: P-5333      DZD\n",
      "1         HP LaserJet Pro           46000.0       Ref: P-7201      DZD\n",
      "2         Dell 24 Monitor           24200.0       Ref: P-1750      DZD\n",
      "3          Canon i-Sensys           39000.0       Ref: P-4814      DZD\n",
      "4           Epson EcoTank           27700.0       Ref: P-6977      DZD\n",
      "\n",
      "======================================================================\n",
      "üìÑ OCR - FACTURES LEGACY (BONUS)\n",
      "======================================================================\n",
      "üìÅ 5 factures d√©tect√©es\n",
      "\n",
      "‚ö†Ô∏è Erreur OCR: No module named 'pytesseract'\n",
      "   Utilisation de donn√©es manuelles...\n",
      "\n",
      "======================================================================\n",
      "üì¶ CHARGEMENT DES DONN√âES EXTRAITES\n",
      "======================================================================\n",
      "‚úÖ sales                 25,000 lignes\n",
      "‚úÖ products                  38 lignes\n",
      "‚úÖ customers              1,200 lignes\n",
      "‚úÖ stores                    12 lignes\n",
      "‚úÖ cities                    12 lignes\n",
      "‚úÖ categories                 5 lignes\n",
      "‚úÖ subcategories             15 lignes\n",
      "‚úÖ reviews                3,000 lignes\n",
      "‚úÖ competitor_prices         38 lignes\n",
      "\n",
      "üìä 9 fichiers charg√©s\n",
      "\n",
      "======================================================================\n",
      "üîÑ EX√âCUTION DU PIPELINE DE TRANSFORMATION\n",
      "======================================================================\n",
      "‚ùå Erreur transformation: No module named 'vaderSentiment'\n",
      "\n",
      "======================================================================\n",
      "üìã V√âRIFICATION DES FICHIERS TRANSFORM√âS\n",
      "======================================================================\n",
      "‚úÖ Dim_Customer           1,110 lignes √ó  5 colonnes\n",
      "‚úÖ Dim_Product               38 lignes √ó 14 colonnes\n",
      "‚úÖ Dim_Store                 12 lignes √ó  8 colonnes\n",
      "‚úÖ Dim_Date                 731 lignes √ó 10 colonnes\n",
      "‚úÖ Fact_Sales            25,000 lignes √ó 12 colonnes\n",
      "‚úÖ Marketing_ROI            162 lignes √ó  5 colonnes\n",
      "\n",
      "üìä 6/6 tables transform√©es\n",
      "\n",
      "======================================================================\n",
      "‚≠ê APER√áU DU SCH√âMA EN √âTOILE\n",
      "======================================================================\n",
      "\n",
      "üìä DIMENSIONS:\n",
      "\n",
      "  Dim_Customer:\n",
      "    Lignes: 1,110\n",
      "    Colonnes: customer_id, full_name, city_id, city_name, region...\n",
      "    Aper√ßu:\n",
      " customer_id   full_name  city_id city_name region\n",
      "           1 Fares Mekki        9    Biskra  South\n",
      "           2 Zineb Oukil       10  Ghardaia  South\n",
      "\n",
      "  Dim_Product:\n",
      "    Lignes: 38\n",
      "    Colonnes: product_id, product_name, subcategory_id, subcategory_name, category_id...\n",
      "    Aper√ßu:\n",
      " product_id product_name  subcategory_id subcategory_name  category_id category_name  unit_price  unit_cost  competitor_price  price_difference  price_difference_pct  avg_sentiment  avg_rating  review_count\n",
      "        100 HP Victus 15               1          Laptops            1     Computers    125000.0    87901.0          119700.0            5300.0                  4.43           0.22        3.54            97\n",
      "        101  Dell XPS 13               1          Laptops            1     Computers    260000.0   167880.0          242700.0           17300.0                  7.13           0.24        3.55            86\n",
      "\n",
      "  Dim_Store:\n",
      "    Lignes: 12\n",
      "    Colonnes: store_id, store_name, city_id, city_name, region...\n",
      "    Aper√ßu:\n",
      " store_id             store_name  city_id city_name region  monthly_target  annual_target   manager_name\n",
      "        1 TechStore Alger Centre        1     Alger  North      6209113.48    74509361.76 Billel Rahmani\n",
      "        2   TechStore Oran Bahia        2      Oran   West      7555913.44    90670961.28 Khadidja Talbi\n",
      "\n",
      "  Dim_Date:\n",
      "    Lignes: 731\n",
      "    Colonnes: date_id, date, year, quarter, month...\n",
      "    Aper√ßu:\n",
      " date_id       date  year  quarter  month month_name  day  day_of_week day_name  week_of_year\n",
      "20230101 2023-01-01  2023        1      1    January    1            7   Sunday            52\n",
      "20230102 2023-01-02  2023        1      1    January    2            1   Monday             1\n",
      "\n",
      "üìä FAIT:\n",
      "\n",
      "  Fact_Sales:\n",
      "    Lignes: 25,000\n",
      "    Colonnes: trans_id, date, store_id, product_id, customer_id, quantity, total_revenue, cost, gross_profit, shipping_cost, marketing_cost, net_profit\n",
      "    Aper√ßu:\n",
      " trans_id       date  store_id  product_id  customer_id  quantity  total_revenue     cost  gross_profit  shipping_cost  marketing_cost  net_profit\n",
      "        1 2024-07-02         3         125          200         2         9000.0   6172.0        2828.0          752.0          119.63     1956.37\n",
      "        2 2023-07-01        11         136          883         1         2500.0   1606.0         894.0          376.0          100.84      417.16\n",
      "        3 2025-01-05         7         106          669         1       320000.0 198987.0      121013.0         1005.0         1949.31   118058.69\n",
      "\n",
      "  üìà Statistiques Financi√®res:\n",
      "    Revenu Total: 859,661,700.00 DZD\n",
      "    Profit Net Total: 259,493,425.49 DZD\n",
      "    Marge Profit: 30.19%\n",
      "\n",
      "======================================================================\n",
      "üóÑÔ∏è CR√âATION DU DATA WAREHOUSE\n",
      "======================================================================\n",
      "======================================================================\n",
      "TECHSTORE DATA WAREHOUSE - DATABASE LOADING\n",
      "Star Schema: 1 Fact Table + 4 Dimension Tables\n",
      "======================================================================\n",
      "\n",
      "[1/4] Loading transformed Star Schema files...\n",
      "  Dim_Customer: 1,110 rows loaded\n",
      "  Dim_Date: 731 rows loaded\n",
      "  Dim_Product: 38 rows loaded\n",
      "  Dim_Store: 12 rows loaded\n",
      "  Fact_Sales: 25,000 rows loaded\n",
      "\n",
      "[2/4] Standardizing column names for database...\n",
      "  Column mapping completed\n",
      "\n",
      "[3/4] Creating SQLite Data Warehouse...\n",
      "  Old database deleted\n",
      "  Connected to: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\database\\techstore_dw.db\n",
      "\n",
      "  Creating Star Schema tables...\n",
      "    Dim_Date created\n",
      "    Dim_Product created\n",
      "    Dim_Store created\n",
      "    Dim_Customer created\n",
      "    Fact_Sales created\n",
      "\n",
      "[4/4] Loading data into tables...\n",
      "  Loading dimensions first (for referential integrity)...\n",
      "    Dim_Date: 731 rows inserted\n",
      "    Dim_Product: 38 rows inserted\n",
      "    Dim_Store: 12 rows inserted\n",
      "    Dim_Customer: 1,110 rows inserted\n",
      "  Loading fact table...\n",
      "    Fact_Sales: 25,000 rows inserted\n",
      "\n",
      "  All data loaded successfully!\n",
      "\n",
      "[Verification] Checking database integrity...\n",
      "\n",
      "  Table Row Counts:\n",
      "  ------------------------------------------------------------\n",
      "    Dim_Date                    731 rows\n",
      "    Dim_Product                  38 rows\n",
      "    Dim_Store                    12 rows\n",
      "    Dim_Customer              1,110 rows\n",
      "    Fact_Sales               25,000 rows\n",
      "  ------------------------------------------------------------\n",
      "\n",
      "  Testing Star Schema joins (Top 5 Sales by Revenue)...\n",
      "  ------------------------------------------------------------\n",
      " Sale_ID  Full_Date Product_Name Category_Name              Store_Name Store_City Region    Customer_Name  Quantity  Revenue    Profit\n",
      "     248 2023-09-16  DJI Mavic 3       Cameras TechStore Tlemcen Ville    Tlemcen   West    Meriem Benali         1 360000.0 139684.52\n",
      "     250 2024-12-28  DJI Mavic 3       Cameras  TechStore Alger Centre      Alger  North Meriem Bouchareb         1 360000.0 137919.34\n",
      "     331 2023-03-09  DJI Mavic 3       Cameras TechStore Tlemcen Ville    Tlemcen   West    Hichem Amrani         1 360000.0 138357.14\n",
      "     606 2023-08-13  DJI Mavic 3       Cameras  TechStore Alger Centre      Alger  North      Sami Benali         1 360000.0 137830.82\n",
      "     756 2023-06-17  DJI Mavic 3       Cameras    TechStore Setif Park      Setif   East   Fatima Guellil         1 360000.0 139599.78\n",
      "\n",
      "  Star Schema joins working correctly!\n",
      "\n",
      "  Business Metrics Summary:\n",
      "  ------------------------------------------------------------\n",
      " Unique_Products  Unique_Stores  Unique_Customers  Total_Transactions  Total_Revenue_M_DZD  Total_Profit_M_DZD  Profit_Margin_Pct  Avg_Transaction_Value\n",
      "              38             12              1200               25000               859.66              259.49              30.19               34386.47\n",
      "\n",
      "  Date Range: 2023-01-01 to 2024-12-31\n",
      "\n",
      "======================================================================\n",
      "DATA WAREHOUSE LOADING COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "Database File: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\database\\techstore_dw.db\n",
      "Date Range: 2023-01-01 to 2024-12-31\n",
      "Total Revenue: 859.66 Million DZD\n",
      "Total Profit: 259.49 Million DZD\n",
      "Profit Margin: 30.19%\n",
      "Stores: 12\n",
      "Products: 38\n",
      "Customers: 1200\n",
      "Transactions: 25,000\n",
      "\n",
      "======================================================================\n",
      "STAR SCHEMA TABLES (5)\n",
      "======================================================================\n",
      "1. Fact_Sales (Fact Table)\n",
      "2. Dim_Date (Time Dimension)\n",
      "3. Dim_Product (Product Dimension)\n",
      "4. Dim_Store (Store Dimension)\n",
      "5. Dim_Customer (Customer Dimension)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Data Warehouse cr√©√© avec succ√®s\n",
      "\n",
      "======================================================================\n",
      "üîç TEST DE CONNEXION AU DATA WAREHOUSE\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Connexion √©tablie: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\database\\techstore_dw.db\n",
      "\n",
      "üìä Tables disponibles (5):\n",
      "  ‚Ä¢ Dim_Customer            1,110 lignes\n",
      "  ‚Ä¢ Dim_Date                  731 lignes\n",
      "  ‚Ä¢ Dim_Product                38 lignes\n",
      "  ‚Ä¢ Dim_Store                  12 lignes\n",
      "  ‚Ä¢ Fact_Sales             25,000 lignes\n",
      "\n",
      "üîó Test de jointure Star Schema:\n",
      " Sale_ID  Full_Date Product_Name                  Store_Name  Customer_Name  Total_Revenue  Net_Profit\n",
      "       1 2024-07-02 Redmi Buds 4 TechStore Constantine Cirta    Ryad Benali         9000.0     1956.37\n",
      "       2 2023-07-01 HP 650 Black       TechStore Ouargla Sud Mohamed Benali         2500.0      417.16\n",
      "       4 2024-08-01 Redmi Buds 4        TechStore Oran Bahia Sarah Zerrouki         4500.0      364.51\n",
      "       5 2023-04-30  Oppo Reno 8      TechStore Biskra Ziban   Amel Brahami        58000.0    19474.00\n",
      "       6 2024-06-25 HP 650 Black       TechStore Ouargla Sud  Fares Khelifa         2500.0      437.77\n",
      "\n",
      "‚úÖ Jointures fonctionnelles!\n",
      "\n",
      "======================================================================\n",
      "‚úÖ VALIDATION DE LA QUALIT√â DES DONN√âES\n",
      "======================================================================\n",
      "\n",
      "        Table  Lignes  Colonnes  Valeurs_Manquantes Pct_Manquant  Doublons_Cl√©s Statut\n",
      " Dim_Customer    1110         5                   0        0.00%              0      ‚úÖ\n",
      "  Dim_Product      38        14                   0        0.00%              0      ‚úÖ\n",
      "    Dim_Store      12         8                   0        0.00%              0      ‚úÖ\n",
      "     Dim_Date     731        10                   0        0.00%              0      ‚úÖ\n",
      "   Fact_Sales   25000        12                   0        0.00%              0      ‚úÖ\n",
      "Marketing_ROI     162         5                   0        0.00%              0      ‚úÖ\n",
      "\n",
      "======================================================================\n",
      "üß™ TESTS DES REQU√äTES SQL\n",
      "======================================================================\n",
      "======================================================================\n",
      "COMPREHENSIVE SQL QUERIES TEST\n",
      "======================================================================\n",
      "Connected to: ../database/techstore_dw.db\n",
      "\n",
      "[1/13] Testing: Total Revenue\n",
      "  Success: 1 rows, 1 columns\n",
      "  Result:\n",
      " Total_Revenue\n",
      "   859661700.0\n",
      "\n",
      "[2/13] Testing: Net Profit\n",
      "  Success: 1 rows, 1 columns\n",
      "  Result:\n",
      "  Net_Profit\n",
      "259493425.49\n",
      "\n",
      "[3/13] Testing: Total Transactions\n",
      "  Success: 1 rows, 1 columns\n",
      "  Result:\n",
      " Total_Transactions\n",
      "              25000\n",
      "\n",
      "[4/13] Testing: Avg Transaction Value\n",
      "  Success: 1 rows, 1 columns\n",
      "  Result:\n",
      " Avg_Transaction_Value\n",
      "              34386.47\n",
      "\n",
      "[5/13] Testing: Monthly Trends\n",
      "  Success: 24 rows, 8 columns\n",
      "\n",
      "[6/13] Testing: Top Selling Products\n",
      "  Success: 15 rows, 6 columns\n",
      "\n",
      "[7/13] Testing: Category Performance\n",
      "  Success: 5 rows, 6 columns\n",
      "\n",
      "[8/13] Testing: Store Ranking\n",
      "  Success: 12 rows, 8 columns\n",
      "\n",
      "[9/13] Testing: Regional Performance\n",
      "  Success: 4 rows, 6 columns\n",
      "\n",
      "[10/13] Testing: Top Customers\n",
      "  Success: 20 rows, 7 columns\n",
      "\n",
      "[11/13] Testing: Profit Margin by Category\n",
      "  Success: 5 rows, 9 columns\n",
      "\n",
      "[12/13] Testing: Marketing ROI\n",
      "  Success: 5 rows, 5 columns\n",
      "\n",
      "[13/13] Testing: Dashboard Summary\n",
      "  Success: 1 rows, 12 columns\n",
      "  Result:\n",
      "Start_Date   End_Date  Total_Transactions  Unique_Customers  Unique_Products  Unique_Stores  Total_Revenue  Total_Profit  Avg_Transaction_Value  Overall_Profit_Margin  Total_Units_Sold  Avg_Quantity_Per_Transaction\n",
      "2023-01-01 2024-12-31               16652              1200               38             12    570222100.0  172099726.93               34243.46                  30.18             27444                          1.65\n",
      "\n",
      "======================================================================\n",
      "TEST SUMMARY\n",
      "======================================================================\n",
      "                    Query Status  Rows  Columns\n",
      "            Total Revenue   Pass     1        1\n",
      "               Net Profit   Pass     1        1\n",
      "       Total Transactions   Pass     1        1\n",
      "    Avg Transaction Value   Pass     1        1\n",
      "           Monthly Trends   Pass    24        8\n",
      "     Top Selling Products   Pass    15        6\n",
      "     Category Performance   Pass     5        6\n",
      "            Store Ranking   Pass    12        8\n",
      "     Regional Performance   Pass     4        6\n",
      "            Top Customers   Pass    20        7\n",
      "Profit Margin by Category   Pass     5        9\n",
      "            Marketing ROI   Pass     5        5\n",
      "        Dashboard Summary   Pass     1       12\n",
      "\n",
      "Passed: 13\n",
      "Failed: 0\n",
      "\n",
      "All queries are working perfectly!\n",
      "Ready for dashboard integration!\n",
      "\n",
      "======================================================================\n",
      "üéâ PIPELINE ETL COMPL√âT√â AVEC SUCC√àS\n",
      "======================================================================\n",
      "\n",
      "‚úÖ EXTRACTION:\n",
      "  ‚úÖ Tables MySQL: 8\n",
      "  ‚úÖ Prix Concurrents: True\n",
      "  ‚úÖ Factures Legacy (OCR): True\n",
      "\n",
      "‚úÖ TRANSFORMATION:\n",
      "  ‚úÖ Dimensions: 4\n",
      "  ‚úÖ Fait: True\n",
      "  ‚úÖ Analyses: True\n",
      "\n",
      "‚úÖ CHARGEMENT:\n",
      "  ‚úÖ Database: True\n",
      "  ‚úÖ Tables: 5\n",
      "\n",
      "üöÄ PROCHAINES √âTAPES:\n",
      "  1. ‚úÖ Lancer le dashboard: streamlit run dashboard/dashboard_app.py\n",
      "  2. ‚úÖ Analyser les KPIs et m√©triques business\n",
      "  3. ‚úÖ G√©n√©rer le rapport final\n",
      "\n",
      "======================================================================\n",
      "üìÅ FICHIERS G√âN√âR√âS:\n",
      "======================================================================\n",
      "  ‚Ä¢ Data Warehouse: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\database\\techstore_dw.db\n",
      "  ‚Ä¢ Donn√©es Extraites: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\Data\\extracted/\n",
      "  ‚Ä¢ Donn√©es Transform√©es: c:\\Users\\DELL\\Desktop\\BI_project\\TechStore\\src\\Data\\transformed/\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # üè™ TechStore - ETL Pipeline Complet\n",
    "# \n",
    "# **Projet**: Business Intelligence - TechStore Data Platform  \n",
    "# **√âquipe**:\n",
    "# - **Sarah Djerrab & Khaoula Merah**: Extraction & Frontend Development  \n",
    "# - **Hadjer Hanani**: Transformation & Feature Engineering  \n",
    "# - **Tasnim Bagha**: Database Architecture  \n",
    "# \n",
    "# **Universit√©**: 8 Mai 1945 Guelma  \n",
    "# **D√©partement**: Intelligence Artificielle (4√®me Ann√©e)  \n",
    "# **Date**: Janvier 2026\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìã Table des Mati√®res\n",
    "# \n",
    "# 1. [Configuration & Imports](#1-configuration)\n",
    "# 2. [Extraction des Donn√©es](#2-extraction)\n",
    "#    - MySQL (ERP)\n",
    "#    - Web Scraping (Prix Concurrents)\n",
    "#    - OCR (Factures Legacy)\n",
    "# 3. [Transformation des Donn√©es](#3-transformation)\n",
    "#    - Nettoyage\n",
    "#    - Enrichissement\n",
    "#    - Analyse de Sentiment\n",
    "#    - Calcul Net Profit\n",
    "# 4. [Chargement dans le Data Warehouse](#4-chargement)\n",
    "# 5. [Validation & Tests](#5-validation)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1Ô∏è‚É£ Configuration & Imports\n",
    "\n",
    "# %%\n",
    "# Imports syst√®me\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des chemins\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SCRIPTS_DIR = PROJECT_ROOT / 'scripts'\n",
    "DATA_DIR = PROJECT_ROOT / 'Data'\n",
    "EXTRACTED_DIR = DATA_DIR / 'extracted'\n",
    "TRANSFORMED_DIR = DATA_DIR / 'transformed'\n",
    "DATABASE_DIR = PROJECT_ROOT / 'database'\n",
    "\n",
    "# Cr√©er les r√©pertoires n√©cessaires\n",
    "for directory in [EXTRACTED_DIR, TRANSFORMED_DIR, DATABASE_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ajouter scripts au path\n",
    "sys.path.insert(0, str(SCRIPTS_DIR))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üè™ TECHSTORE - ETL PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìÅ Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"üìÖ Execution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2Ô∏è‚É£ Extraction des Donn√©es\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.1 Extraction MySQL (ERP)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä EXTRACTION MYSQL (ERP)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Configuration MySQL\n",
    "MYSQL_CONFIG = {\n",
    "    'host': 'boughida.com',\n",
    "    'database': 'techstore_erp',\n",
    "    'user': 'student_user_4ing',\n",
    "    'password': 'bi_guelma_2025'\n",
    "}\n",
    "\n",
    "try:\n",
    "    from extract_mysql import MySQLExtractor\n",
    "    \n",
    "    # Cr√©er l'extracteur\n",
    "    extractor = MySQLExtractor(**MYSQL_CONFIG)\n",
    "    \n",
    "    if extractor.connect():\n",
    "        print(\"‚úÖ Connexion MySQL √©tablie\\n\")\n",
    "        \n",
    "        # Extraire toutes les tables\n",
    "        extraction_summary = extractor.extract_all_tables()\n",
    "        \n",
    "        # Fermer la connexion\n",
    "        extractor.close()\n",
    "        \n",
    "        print(f\"\\n‚úÖ {len(extraction_summary)} tables extraites avec succ√®s\")\n",
    "    else:\n",
    "        print(\"‚ùå √âchec de connexion MySQL\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur extraction MySQL: {e}\")\n",
    "    print(\"   Assurez-vous que scripts/extract_mysql.py existe\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.2 Web Scraping (Prix Concurrents)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üï∑Ô∏è WEB SCRAPING - PRIX CONCURRENTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    from scrape_competitors import scrape_with_fallback\n",
    "    \n",
    "    # Ex√©cuter le scraping avec fallback\n",
    "    df_competitor = scrape_with_fallback()\n",
    "    \n",
    "    if df_competitor is not None and len(df_competitor) > 0:\n",
    "        print(f\"\\n‚úÖ {len(df_competitor)} prix concurrents extraits\")\n",
    "        print(f\"üíæ Fichier: {EXTRACTED_DIR / 'competitor_prices.csv'}\")\n",
    "        print(\"\\nüìä Aper√ßu:\")\n",
    "        print(df_competitor.head())\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune donn√©e concurrent r√©cup√©r√©e\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur scraping: {e}\")\n",
    "    print(\"   Assurez-vous que scripts/scrape_competitors.py existe\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.3 OCR - Factures Legacy (BONUS)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìÑ OCR - FACTURES LEGACY (BONUS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# V√©rifier si des factures existent\n",
    "invoice_dir = DATA_DIR / 'legacy_invoices'\n",
    "has_invoices = invoice_dir.exists() and len(list(invoice_dir.glob('*.jpg'))) > 0\n",
    "\n",
    "if has_invoices:\n",
    "    print(f\"üìÅ {len(list(invoice_dir.glob('*.jpg')))} factures d√©tect√©es\\n\")\n",
    "    \n",
    "    try:\n",
    "        from extract_legacy_invoices import InvoiceOCRProcessor\n",
    "        \n",
    "        # Initialiser et ex√©cuter OCR\n",
    "        processor = InvoiceOCRProcessor(str(invoice_dir))\n",
    "        df_legacy = processor.process_and_save()\n",
    "        \n",
    "        if df_legacy is not None and len(df_legacy) > 0:\n",
    "            print(f\"\\n‚úÖ {len(df_legacy)} factures trait√©es\")\n",
    "            print(f\"üíæ Fichier: {EXTRACTED_DIR / 'legacy_sales.csv'}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Aucune donn√©e extraite par OCR\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur OCR: {e}\")\n",
    "        print(\"   Utilisation de donn√©es manuelles...\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Aucune facture trouv√©e (√©tape optionnelle)\")\n",
    "    print(f\"   Pour activer: placez les images dans {invoice_dir}/\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3Ô∏è‚É£ Transformation des Donn√©es\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.1 Chargement des Donn√©es Extraites\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ CHARGEMENT DES DONN√âES EXTRAITES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Charger toutes les donn√©es extraites\n",
    "dataframes = {}\n",
    "\n",
    "csv_files = {\n",
    "    'sales': 'sales.csv',\n",
    "    'products': 'products.csv',\n",
    "    'customers': 'customers.csv',\n",
    "    'stores': 'stores.csv',\n",
    "    'cities': 'cities.csv',\n",
    "    'categories': 'categories.csv',\n",
    "    'subcategories': 'subcategories.csv',\n",
    "    'reviews': 'reviews.csv',\n",
    "    'competitor_prices': 'competitor_prices.csv'\n",
    "}\n",
    "\n",
    "for name, filename in csv_files.items():\n",
    "    filepath = EXTRACTED_DIR / filename\n",
    "    if filepath.exists():\n",
    "        dataframes[name] = pd.read_csv(filepath)\n",
    "        print(f\"‚úÖ {name:20} {len(dataframes[name]):>7,} lignes\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {name:20} Fichier non trouv√©\")\n",
    "\n",
    "print(f\"\\nüìä {len(dataframes)} fichiers charg√©s\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.2 Ex√©cution du Pipeline de Transformation\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîÑ EX√âCUTION DU PIPELINE DE TRANSFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Changer le r√©pertoire vers scripts pour l'import\n",
    "    os.chdir(SCRIPTS_DIR)\n",
    "    \n",
    "    # Importer et ex√©cuter transform_data\n",
    "    import transform_data\n",
    "    \n",
    "    # Ex√©cuter le pipeline principal\n",
    "    transform_data.main()\n",
    "    \n",
    "    # Retour au r√©pertoire racine\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "    print(\"\\n‚úÖ Transformation termin√©e avec succ√®s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur transformation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.3 V√©rification des Fichiers Transform√©s\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã V√âRIFICATION DES FICHIERS TRANSFORM√âS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "transformed_files = {\n",
    "    'Dim_Customer': 'Dim_Customer.csv',\n",
    "    'Dim_Product': 'Dim_Product.csv',\n",
    "    'Dim_Store': 'Dim_Store.csv',\n",
    "    'Dim_Date': 'Dim_Date.csv',\n",
    "    'Fact_Sales': 'Fact_Sales.csv',\n",
    "    'Marketing_ROI': 'marketing_roi.csv'\n",
    "}\n",
    "\n",
    "transformed_data = {}\n",
    "\n",
    "for name, filename in transformed_files.items():\n",
    "    filepath = TRANSFORMED_DIR / filename\n",
    "    if filepath.exists():\n",
    "        df = pd.read_csv(filepath)\n",
    "        transformed_data[name] = df\n",
    "        print(f\"‚úÖ {name:20} {len(df):>7,} lignes √ó {len(df.columns):>2} colonnes\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name:20} Fichier non trouv√©\")\n",
    "\n",
    "print(f\"\\nüìä {len(transformed_data)}/6 tables transform√©es\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.4 Aper√ßu du Sch√©ma en √âtoile\n",
    "\n",
    "# %%\n",
    "if len(transformed_data) >= 5:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚≠ê APER√áU DU SCH√âMA EN √âTOILE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Dimensions\n",
    "    print(\"\\nüìä DIMENSIONS:\")\n",
    "    for dim in ['Dim_Customer', 'Dim_Product', 'Dim_Store', 'Dim_Date']:\n",
    "        if dim in transformed_data:\n",
    "            df = transformed_data[dim]\n",
    "            print(f\"\\n  {dim}:\")\n",
    "            print(f\"    Lignes: {len(df):,}\")\n",
    "            print(f\"    Colonnes: {', '.join(df.columns.tolist()[:5])}...\")\n",
    "            print(f\"    Aper√ßu:\")\n",
    "            print(df.head(2).to_string(index=False))\n",
    "    \n",
    "    # Fait\n",
    "    print(\"\\nüìä FAIT:\")\n",
    "    if 'Fact_Sales' in transformed_data:\n",
    "        df = transformed_data['Fact_Sales']\n",
    "        print(f\"\\n  Fact_Sales:\")\n",
    "        print(f\"    Lignes: {len(df):,}\")\n",
    "        print(f\"    Colonnes: {', '.join(df.columns.tolist())}\")\n",
    "        print(f\"    Aper√ßu:\")\n",
    "        print(df.head(3).to_string(index=False))\n",
    "        \n",
    "        # Statistiques financi√®res\n",
    "        print(f\"\\n  üìà Statistiques Financi√®res:\")\n",
    "        print(f\"    Revenu Total: {df['total_revenue'].sum():,.2f} DZD\")\n",
    "        print(f\"    Profit Net Total: {df['net_profit'].sum():,.2f} DZD\")\n",
    "        print(f\"    Marge Profit: {(df['net_profit'].sum() / df['total_revenue'].sum() * 100):.2f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4Ô∏è‚É£ Chargement dans le Data Warehouse\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 4.1 Cr√©ation de la Base de Donn√©es SQLite\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üóÑÔ∏è CR√âATION DU DATA WAREHOUSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Changer vers scripts\n",
    "    os.chdir(SCRIPTS_DIR)\n",
    "    \n",
    "    # Ex√©cuter create_database.py\n",
    "    exec(open('create_database.py').read())\n",
    "    \n",
    "    # Retour au r√©pertoire racine\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "    print(\"\\n‚úÖ Data Warehouse cr√©√© avec succ√®s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur cr√©ation DB: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 4.2 Test de Connexion au Data Warehouse\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîç TEST DE CONNEXION AU DATA WAREHOUSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    import sqlite3\n",
    "    \n",
    "    db_path = DATABASE_DIR / 'techstore_dw.db'\n",
    "    \n",
    "    if db_path.exists():\n",
    "        conn = sqlite3.connect(str(db_path))\n",
    "        \n",
    "        # Lister les tables\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Connexion √©tablie: {db_path}\")\n",
    "        print(f\"\\nüìä Tables disponibles ({len(tables)}):\")\n",
    "        \n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(f\"  ‚Ä¢ {table_name:20} {count:>8,} lignes\")\n",
    "        \n",
    "        # Test de requ√™te Star Schema\n",
    "        print(\"\\nüîó Test de jointure Star Schema:\")\n",
    "        test_query = \"\"\"\n",
    "        SELECT \n",
    "            fs.Sale_ID,\n",
    "            dd.Full_Date,\n",
    "            dp.Product_Name,\n",
    "            ds.Store_Name,\n",
    "            dc.Customer_Name,\n",
    "            fs.Total_Revenue,\n",
    "            fs.Net_Profit\n",
    "        FROM Fact_Sales fs\n",
    "        JOIN Dim_Date dd ON fs.Date_ID = dd.Date_ID\n",
    "        JOIN Dim_Product dp ON fs.Product_ID = dp.Product_ID\n",
    "        JOIN Dim_Store ds ON fs.Store_ID = ds.Store_ID\n",
    "        JOIN Dim_Customer dc ON fs.Customer_ID = dc.Customer_ID\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        \n",
    "        test_df = pd.read_sql(test_query, conn)\n",
    "        print(test_df.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n‚úÖ Jointures fonctionnelles!\")\n",
    "        \n",
    "        conn.close()\n",
    "    else:\n",
    "        print(f\"‚ùå Base de donn√©es non trouv√©e: {db_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur test DB: {e}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5Ô∏è‚É£ Validation & Tests\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 5.1 Tests de Qualit√© des Donn√©es\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ VALIDATION DE LA QUALIT√â DES DONN√âES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for name, df in transformed_data.items():\n",
    "    # Valeurs manquantes\n",
    "    missing = df.isnull().sum().sum()\n",
    "    missing_pct = (missing / (df.shape[0] * df.shape[1])) * 100\n",
    "    \n",
    "    # Doublons\n",
    "    if 'Customer_ID' in df.columns:\n",
    "        duplicates = df['Customer_ID'].duplicated().sum()\n",
    "    elif 'Product_ID' in df.columns:\n",
    "        duplicates = df['Product_ID'].duplicated().sum()\n",
    "    elif 'Store_ID' in df.columns:\n",
    "        duplicates = df['Store_ID'].duplicated().sum()\n",
    "    elif 'Date_ID' in df.columns:\n",
    "        duplicates = df['Date_ID'].duplicated().sum()\n",
    "    elif 'Sale_ID' in df.columns:\n",
    "        duplicates = df['Sale_ID'].duplicated().sum()\n",
    "    else:\n",
    "        duplicates = 0\n",
    "    \n",
    "    validation_results.append({\n",
    "        'Table': name,\n",
    "        'Lignes': len(df),\n",
    "        'Colonnes': len(df.columns),\n",
    "        'Valeurs_Manquantes': missing,\n",
    "        'Pct_Manquant': f\"{missing_pct:.2f}%\",\n",
    "        'Doublons_Cl√©s': duplicates,\n",
    "        'Statut': '‚úÖ' if missing_pct < 5 and duplicates == 0 else '‚ö†Ô∏è'\n",
    "    })\n",
    "\n",
    "df_validation = pd.DataFrame(validation_results)\n",
    "print(\"\\n\" + df_validation.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 5.2 Tests des Requ√™tes SQL\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß™ TESTS DES REQU√äTES SQL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    os.chdir(SCRIPTS_DIR)\n",
    "    \n",
    "    # Ex√©cuter test_queries.py\n",
    "    exec(open('test_queries.py').read())\n",
    "    \n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur tests SQL: {e}\")\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìä R√©sum√© Final du Pipeline ETL\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ PIPELINE ETL COMPL√âT√â AVEC SUCC√àS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = {\n",
    "    'Extraction': {\n",
    "        'Tables MySQL': len([k for k in dataframes.keys() if k not in ['competitor_prices']]),\n",
    "        'Prix Concurrents': 'competitor_prices' in dataframes,\n",
    "        'Factures Legacy (OCR)': (DATA_DIR / 'extracted' / 'legacy_sales.csv').exists()\n",
    "    },\n",
    "    'Transformation': {\n",
    "        'Dimensions': len([k for k in transformed_data.keys() if k.startswith('Dim_')]),\n",
    "        'Fait': 'Fact_Sales' in transformed_data,\n",
    "        'Analyses': 'Marketing_ROI' in transformed_data\n",
    "    },\n",
    "    'Chargement': {\n",
    "        'Database': (DATABASE_DIR / 'techstore_dw.db').exists(),\n",
    "        'Tables': len(tables) if 'tables' in locals() else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ EXTRACTION:\")\n",
    "for key, value in summary['Extraction'].items():\n",
    "    status = \"‚úÖ\" if value else \"‚è≠Ô∏è\"\n",
    "    print(f\"  {status} {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ TRANSFORMATION:\")\n",
    "for key, value in summary['Transformation'].items():\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\"\n",
    "    print(f\"  {status} {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ CHARGEMENT:\")\n",
    "for key, value in summary['Chargement'].items():\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\"\n",
    "    print(f\"  {status} {key}: {value}\")\n",
    "\n",
    "print(\"\\nüöÄ PROCHAINES √âTAPES:\")\n",
    "print(\"  1. ‚úÖ Lancer le dashboard: streamlit run dashboard/dashboard_app.py\")\n",
    "print(\"  2. ‚úÖ Analyser les KPIs et m√©triques business\")\n",
    "print(\"  3. ‚úÖ G√©n√©rer le rapport final\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìÅ FICHIERS G√âN√âR√âS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  ‚Ä¢ Data Warehouse: {DATABASE_DIR / 'techstore_dw.db'}\")\n",
    "print(f\"  ‚Ä¢ Donn√©es Extraites: {EXTRACTED_DIR}/\")\n",
    "print(f\"  ‚Ä¢ Donn√©es Transform√©es: {TRANSFORMED_DIR}/\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
