{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da295553",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# === Partie 1 : Extraction (Membre 1) ===\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmysql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # üè™ TechStore - ETL Pipeline Complet\n",
    "# \n",
    "# **Projet**: Business Intelligence - TechStore Data Platform  \n",
    "# **√âquipe**:\n",
    "# - **Sarah Djerrab & Khaoula Merah**: Extraction & Frontend Development  \n",
    "# - **Hadjer Hanani**: Transformation & Feature Engineering  \n",
    "# - **Tasnim Bagha**: Database Architecture  \n",
    "# \n",
    "# **Universit√©**: 8 Mai 1945 Guelma  \n",
    "# **D√©partement**: Intelligence Artificielle (4√®me Ann√©e)  \n",
    "# **Date**: Janvier 2026\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìã Table des Mati√®res\n",
    "# \n",
    "# 1. [Configuration & Imports](#1-configuration)\n",
    "# 2. [Extraction des Donn√©es](#2-extraction)\n",
    "#    - MySQL (ERP)\n",
    "#    - Web Scraping (Prix Concurrents)\n",
    "#    - OCR (Factures Legacy)\n",
    "# 3. [Transformation des Donn√©es](#3-transformation)\n",
    "#    - Nettoyage\n",
    "#    - Enrichissement\n",
    "#    - Analyse de Sentiment\n",
    "#    - Calcul Net Profit\n",
    "# 4. [Chargement dans le Data Warehouse](#4-chargement)\n",
    "# 5. [Validation & Tests](#5-validation)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1Ô∏è‚É£ Configuration & Imports\n",
    "\n",
    "# %%\n",
    "# Imports syst√®me\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des chemins\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "SCRIPTS_DIR = PROJECT_ROOT / 'scripts'\n",
    "DATA_DIR = PROJECT_ROOT / 'Data'\n",
    "EXTRACTED_DIR = DATA_DIR / 'extracted'\n",
    "TRANSFORMED_DIR = DATA_DIR / 'transformed'\n",
    "DATABASE_DIR = PROJECT_ROOT / 'database'\n",
    "\n",
    "# Cr√©er les r√©pertoires n√©cessaires\n",
    "for directory in [EXTRACTED_DIR, TRANSFORMED_DIR, DATABASE_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ajouter scripts au path\n",
    "sys.path.insert(0, str(SCRIPTS_DIR))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üè™ TECHSTORE - ETL PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìÅ Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"üìÖ Execution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2Ô∏è‚É£ Extraction des Donn√©es\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.1 Extraction MySQL (ERP)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä EXTRACTION MYSQL (ERP)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Configuration MySQL\n",
    "MYSQL_CONFIG = {\n",
    "    'host': 'boughida.com',\n",
    "    'database': 'techstore_erp',\n",
    "    'user': 'student_user_4ing',\n",
    "    'password': 'bi_guelma_2025'\n",
    "}\n",
    "\n",
    "try:\n",
    "    from extract_mysql import MySQLExtractor\n",
    "    \n",
    "    # Cr√©er l'extracteur\n",
    "    extractor = MySQLExtractor(**MYSQL_CONFIG)\n",
    "    \n",
    "    if extractor.connect():\n",
    "        print(\"‚úÖ Connexion MySQL √©tablie\\n\")\n",
    "        \n",
    "        # Extraire toutes les tables\n",
    "        extraction_summary = extractor.extract_all_tables()\n",
    "        \n",
    "        # Fermer la connexion\n",
    "        extractor.close()\n",
    "        \n",
    "        print(f\"\\n‚úÖ {len(extraction_summary)} tables extraites avec succ√®s\")\n",
    "    else:\n",
    "        print(\"‚ùå √âchec de connexion MySQL\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur extraction MySQL: {e}\")\n",
    "    print(\"   Assurez-vous que scripts/extract_mysql.py existe\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.2 Web Scraping (Prix Concurrents)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üï∑Ô∏è WEB SCRAPING - PRIX CONCURRENTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    from scrape_competitors import scrape_with_fallback\n",
    "    \n",
    "    # Ex√©cuter le scraping avec fallback\n",
    "    df_competitor = scrape_with_fallback()\n",
    "    \n",
    "    if df_competitor is not None and len(df_competitor) > 0:\n",
    "        print(f\"\\n‚úÖ {len(df_competitor)} prix concurrents extraits\")\n",
    "        print(f\"üíæ Fichier: {EXTRACTED_DIR / 'competitor_prices.csv'}\")\n",
    "        print(\"\\nüìä Aper√ßu:\")\n",
    "        print(df_competitor.head())\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune donn√©e concurrent r√©cup√©r√©e\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur scraping: {e}\")\n",
    "    print(\"   Assurez-vous que scripts/scrape_competitors.py existe\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 2.3 OCR - Factures Legacy (BONUS)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìÑ OCR - FACTURES LEGACY (BONUS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# V√©rifier si des factures existent\n",
    "invoice_dir = DATA_DIR / 'legacy_invoices'\n",
    "has_invoices = invoice_dir.exists() and len(list(invoice_dir.glob('*.jpg'))) > 0\n",
    "\n",
    "if has_invoices:\n",
    "    print(f\"üìÅ {len(list(invoice_dir.glob('*.jpg')))} factures d√©tect√©es\\n\")\n",
    "    \n",
    "    try:\n",
    "        from extract_legacy_invoices import InvoiceOCRProcessor\n",
    "        \n",
    "        # Initialiser et ex√©cuter OCR\n",
    "        processor = InvoiceOCRProcessor(str(invoice_dir))\n",
    "        df_legacy = processor.process_and_save()\n",
    "        \n",
    "        if df_legacy is not None and len(df_legacy) > 0:\n",
    "            print(f\"\\n‚úÖ {len(df_legacy)} factures trait√©es\")\n",
    "            print(f\"üíæ Fichier: {EXTRACTED_DIR / 'legacy_sales.csv'}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Aucune donn√©e extraite par OCR\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur OCR: {e}\")\n",
    "        print(\"   Utilisation de donn√©es manuelles...\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Aucune facture trouv√©e (√©tape optionnelle)\")\n",
    "    print(f\"   Pour activer: placez les images dans {invoice_dir}/\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3Ô∏è‚É£ Transformation des Donn√©es\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.1 Chargement des Donn√©es Extraites\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üì¶ CHARGEMENT DES DONN√âES EXTRAITES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Charger toutes les donn√©es extraites\n",
    "dataframes = {}\n",
    "\n",
    "csv_files = {\n",
    "    'sales': 'sales.csv',\n",
    "    'products': 'products.csv',\n",
    "    'customers': 'customers.csv',\n",
    "    'stores': 'stores.csv',\n",
    "    'cities': 'cities.csv',\n",
    "    'categories': 'categories.csv',\n",
    "    'subcategories': 'subcategories.csv',\n",
    "    'reviews': 'reviews.csv',\n",
    "    'competitor_prices': 'competitor_prices.csv'\n",
    "}\n",
    "\n",
    "for name, filename in csv_files.items():\n",
    "    filepath = EXTRACTED_DIR / filename\n",
    "    if filepath.exists():\n",
    "        dataframes[name] = pd.read_csv(filepath)\n",
    "        print(f\"‚úÖ {name:20} {len(dataframes[name]):>7,} lignes\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {name:20} Fichier non trouv√©\")\n",
    "\n",
    "print(f\"\\nüìä {len(dataframes)} fichiers charg√©s\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.2 Ex√©cution du Pipeline de Transformation\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîÑ EX√âCUTION DU PIPELINE DE TRANSFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Changer le r√©pertoire vers scripts pour l'import\n",
    "    os.chdir(SCRIPTS_DIR)\n",
    "    \n",
    "    # Importer et ex√©cuter transform_data\n",
    "    import transform_data\n",
    "    \n",
    "    # Ex√©cuter le pipeline principal\n",
    "    transform_data.main()\n",
    "    \n",
    "    # Retour au r√©pertoire racine\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "    print(\"\\n‚úÖ Transformation termin√©e avec succ√®s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur transformation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.3 V√©rification des Fichiers Transform√©s\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìã V√âRIFICATION DES FICHIERS TRANSFORM√âS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "transformed_files = {\n",
    "    'Dim_Customer': 'Dim_Customer.csv',\n",
    "    'Dim_Product': 'Dim_Product.csv',\n",
    "    'Dim_Store': 'Dim_Store.csv',\n",
    "    'Dim_Date': 'Dim_Date.csv',\n",
    "    'Fact_Sales': 'Fact_Sales.csv',\n",
    "    'Marketing_ROI': 'marketing_roi.csv'\n",
    "}\n",
    "\n",
    "transformed_data = {}\n",
    "\n",
    "for name, filename in transformed_files.items():\n",
    "    filepath = TRANSFORMED_DIR / filename\n",
    "    if filepath.exists():\n",
    "        df = pd.read_csv(filepath)\n",
    "        transformed_data[name] = df\n",
    "        print(f\"‚úÖ {name:20} {len(df):>7,} lignes √ó {len(df.columns):>2} colonnes\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name:20} Fichier non trouv√©\")\n",
    "\n",
    "print(f\"\\nüìä {len(transformed_data)}/6 tables transform√©es\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.4 Aper√ßu du Sch√©ma en √âtoile\n",
    "\n",
    "# %%\n",
    "if len(transformed_data) >= 5:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚≠ê APER√áU DU SCH√âMA EN √âTOILE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Dimensions\n",
    "    print(\"\\nüìä DIMENSIONS:\")\n",
    "    for dim in ['Dim_Customer', 'Dim_Product', 'Dim_Store', 'Dim_Date']:\n",
    "        if dim in transformed_data:\n",
    "            df = transformed_data[dim]\n",
    "            print(f\"\\n  {dim}:\")\n",
    "            print(f\"    Lignes: {len(df):,}\")\n",
    "            print(f\"    Colonnes: {', '.join(df.columns.tolist()[:5])}...\")\n",
    "            print(f\"    Aper√ßu:\")\n",
    "            print(df.head(2).to_string(index=False))\n",
    "    \n",
    "    # Fait\n",
    "    print(\"\\nüìä FAIT:\")\n",
    "    if 'Fact_Sales' in transformed_data:\n",
    "        df = transformed_data['Fact_Sales']\n",
    "        print(f\"\\n  Fact_Sales:\")\n",
    "        print(f\"    Lignes: {len(df):,}\")\n",
    "        print(f\"    Colonnes: {', '.join(df.columns.tolist())}\")\n",
    "        print(f\"    Aper√ßu:\")\n",
    "        print(df.head(3).to_string(index=False))\n",
    "        \n",
    "        # Statistiques financi√®res\n",
    "        print(f\"\\n  üìà Statistiques Financi√®res:\")\n",
    "        print(f\"    Revenu Total: {df['total_revenue'].sum():,.2f} DZD\")\n",
    "        print(f\"    Profit Net Total: {df['net_profit'].sum():,.2f} DZD\")\n",
    "        print(f\"    Marge Profit: {(df['net_profit'].sum() / df['total_revenue'].sum() * 100):.2f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4Ô∏è‚É£ Chargement dans le Data Warehouse\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 4.1 Cr√©ation de la Base de Donn√©es SQLite\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üóÑÔ∏è CR√âATION DU DATA WAREHOUSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Changer vers scripts\n",
    "    os.chdir(SCRIPTS_DIR)\n",
    "    \n",
    "    # Ex√©cuter create_database.py\n",
    "    exec(open('create_database.py').read())\n",
    "    \n",
    "    # Retour au r√©pertoire racine\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "    print(\"\\n‚úÖ Data Warehouse cr√©√© avec succ√®s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur cr√©ation DB: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 4.2 Test de Connexion au Data Warehouse\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîç TEST DE CONNEXION AU DATA WAREHOUSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    import sqlite3\n",
    "    \n",
    "    db_path = DATABASE_DIR / 'techstore_dw.db'\n",
    "    \n",
    "    if db_path.exists():\n",
    "        conn = sqlite3.connect(str(db_path))\n",
    "        \n",
    "        # Lister les tables\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Connexion √©tablie: {db_path}\")\n",
    "        print(f\"\\nüìä Tables disponibles ({len(tables)}):\")\n",
    "        \n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(f\"  ‚Ä¢ {table_name:20} {count:>8,} lignes\")\n",
    "        \n",
    "        # Test de requ√™te Star Schema\n",
    "        print(\"\\nüîó Test de jointure Star Schema:\")\n",
    "        test_query = \"\"\"\n",
    "        SELECT \n",
    "            fs.Sale_ID,\n",
    "            dd.Full_Date,\n",
    "            dp.Product_Name,\n",
    "            ds.Store_Name,\n",
    "            dc.Customer_Name,\n",
    "            fs.Total_Revenue,\n",
    "            fs.Net_Profit\n",
    "        FROM Fact_Sales fs\n",
    "        JOIN Dim_Date dd ON fs.Date_ID = dd.Date_ID\n",
    "        JOIN Dim_Product dp ON fs.Product_ID = dp.Product_ID\n",
    "        JOIN Dim_Store ds ON fs.Store_ID = ds.Store_ID\n",
    "        JOIN Dim_Customer dc ON fs.Customer_ID = dc.Customer_ID\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        \n",
    "        test_df = pd.read_sql(test_query, conn)\n",
    "        print(test_df.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n‚úÖ Jointures fonctionnelles!\")\n",
    "        \n",
    "        conn.close()\n",
    "    else:\n",
    "        print(f\"‚ùå Base de donn√©es non trouv√©e: {db_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur test DB: {e}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5Ô∏è‚É£ Validation & Tests\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 5.1 Tests de Qualit√© des Donn√©es\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ VALIDATION DE LA QUALIT√â DES DONN√âES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for name, df in transformed_data.items():\n",
    "    # Valeurs manquantes\n",
    "    missing = df.isnull().sum().sum()\n",
    "    missing_pct = (missing / (df.shape[0] * df.shape[1])) * 100\n",
    "    \n",
    "    # Doublons\n",
    "    if 'Customer_ID' in df.columns:\n",
    "        duplicates = df['Customer_ID'].duplicated().sum()\n",
    "    elif 'Product_ID' in df.columns:\n",
    "        duplicates = df['Product_ID'].duplicated().sum()\n",
    "    elif 'Store_ID' in df.columns:\n",
    "        duplicates = df['Store_ID'].duplicated().sum()\n",
    "    elif 'Date_ID' in df.columns:\n",
    "        duplicates = df['Date_ID'].duplicated().sum()\n",
    "    elif 'Sale_ID' in df.columns:\n",
    "        duplicates = df['Sale_ID'].duplicated().sum()\n",
    "    else:\n",
    "        duplicates = 0\n",
    "    \n",
    "    validation_results.append({\n",
    "        'Table': name,\n",
    "        'Lignes': len(df),\n",
    "        'Colonnes': len(df.columns),\n",
    "        'Valeurs_Manquantes': missing,\n",
    "        'Pct_Manquant': f\"{missing_pct:.2f}%\",\n",
    "        'Doublons_Cl√©s': duplicates,\n",
    "        'Statut': '‚úÖ' if missing_pct < 5 and duplicates == 0 else '‚ö†Ô∏è'\n",
    "    })\n",
    "\n",
    "df_validation = pd.DataFrame(validation_results)\n",
    "print(\"\\n\" + df_validation.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 5.2 Tests des Requ√™tes SQL\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß™ TESTS DES REQU√äTES SQL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    os.chdir(SCRIPTS_DIR)\n",
    "    \n",
    "    # Ex√©cuter test_queries.py\n",
    "    exec(open('test_queries.py').read())\n",
    "    \n",
    "    os.chdir(PROJECT_ROOT)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur tests SQL: {e}\")\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìä R√©sum√© Final du Pipeline ETL\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ PIPELINE ETL COMPL√âT√â AVEC SUCC√àS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = {\n",
    "    'Extraction': {\n",
    "        'Tables MySQL': len([k for k in dataframes.keys() if k not in ['competitor_prices']]),\n",
    "        'Prix Concurrents': 'competitor_prices' in dataframes,\n",
    "        'Factures Legacy (OCR)': (DATA_DIR / 'extracted' / 'legacy_sales.csv').exists()\n",
    "    },\n",
    "    'Transformation': {\n",
    "        'Dimensions': len([k for k in transformed_data.keys() if k.startswith('Dim_')]),\n",
    "        'Fait': 'Fact_Sales' in transformed_data,\n",
    "        'Analyses': 'Marketing_ROI' in transformed_data\n",
    "    },\n",
    "    'Chargement': {\n",
    "        'Database': (DATABASE_DIR / 'techstore_dw.db').exists(),\n",
    "        'Tables': len(tables) if 'tables' in locals() else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ EXTRACTION:\")\n",
    "for key, value in summary['Extraction'].items():\n",
    "    status = \"‚úÖ\" if value else \"‚è≠Ô∏è\"\n",
    "    print(f\"  {status} {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ TRANSFORMATION:\")\n",
    "for key, value in summary['Transformation'].items():\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\"\n",
    "    print(f\"  {status} {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ CHARGEMENT:\")\n",
    "for key, value in summary['Chargement'].items():\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\"\n",
    "    print(f\"  {status} {key}: {value}\")\n",
    "\n",
    "print(\"\\nüöÄ PROCHAINES √âTAPES:\")\n",
    "print(\"  1. ‚úÖ Lancer le dashboard: streamlit run dashboard/dashboard_app.py\")\n",
    "print(\"  2. ‚úÖ Analyser les KPIs et m√©triques business\")\n",
    "print(\"  3. ‚úÖ G√©n√©rer le rapport final\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìÅ FICHIERS G√âN√âR√âS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  ‚Ä¢ Data Warehouse: {DATABASE_DIR / 'techstore_dw.db'}\")\n",
    "print(f\"  ‚Ä¢ Donn√©es Extraites: {EXTRACTED_DIR}/\")\n",
    "print(f\"  ‚Ä¢ Donn√©es Transform√©es: {TRANSFORMED_DIR}/\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
