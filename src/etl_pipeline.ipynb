{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da295553",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# === Partie 1 : Extraction (Membre 1) ===\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmysql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# PROJET BUSINESS INTELLIGENCE - TECHSTORE\n",
    "# ETL PIPELINE - PARTIE MEMBRE 1 : DATA EXTRACTION\n",
    "# ====================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # üìä Extraction des Donn√©es (Membre 1)\n",
    "# \n",
    "# Ce notebook contient la partie extraction du pipeline ETL.\n",
    "# **Responsable :** Membre 1 - Data Extraction Engineer\n",
    "# \n",
    "# ## Objectifs :\n",
    "# 1. ‚úÖ Extraire les donn√©es de MySQL (ERP)\n",
    "# 2. ‚úÖ Scraper les prix des concurrents\n",
    "# 3. ‚úÖ Extraire les factures legacy (OCR - BONUS)\n",
    "# 4. ‚úÖ Valider la qualit√© des donn√©es extraites\n",
    "\n",
    "# %% Imports pour tout le pipeline ETL\n",
    "# Installer les d√©pendances manquantes (ex√©cuter uniquement dans le notebook)\n",
    "\n",
    "\n",
    "# === Imports de base ===\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Partie 1 : Extraction (Membre 1) ===\n",
    "import mysql.connector\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# === Partie 2 : Transformations (Membre 2 - Toi) ===\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "from fuzzywuzzy import process  # Pour le matching des prix concurrents\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n",
    "print(f\"üìÖ Date d'ex√©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1Ô∏è‚É£ Configuration de la Connexion MySQL\n",
    "\n",
    "# %% Configuration\n",
    "MYSQL_CONFIG = {\n",
    "    'host': 'boughida.com',\n",
    "    'database': 'techstore_erp',\n",
    "    'user': 'student_user_4ing',\n",
    "    'password': 'bi_guelma_2025'\n",
    "}\n",
    "\n",
    "# Cr√©er les r√©pertoires n√©cessaires\n",
    "os.makedirs('data/extracted', exist_ok=True)\n",
    "os.makedirs('data/legacy_invoices', exist_ok=True)\n",
    "\n",
    "print(\"üìã Configuration charg√©e\")\n",
    "print(f\"   Serveur: {MYSQL_CONFIG['host']}\")\n",
    "print(f\"   Base de donn√©es: {MYSQL_CONFIG['database']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2Ô∏è‚É£ Connexion et Test\n",
    "\n",
    "# %% Test de connexion\n",
    "def test_connection():\n",
    "    \"\"\"Tester la connexion √† MySQL\"\"\"\n",
    "    try:\n",
    "        conn = mysql.connector.connect(**MYSQL_CONFIG)\n",
    "        if conn.is_connected():\n",
    "            print(\"‚úÖ Connexion MySQL r√©ussie!\")\n",
    "            \n",
    "            # Tester une requ√™te simple\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT DATABASE()\")\n",
    "            db_name = cursor.fetchone()[0]\n",
    "            print(f\"   Base de donn√©es active: {db_name}\")\n",
    "            \n",
    "            # Lister les tables disponibles\n",
    "            cursor.execute(\"SHOW TABLES\")\n",
    "            tables = cursor.fetchall()\n",
    "            print(f\"   Nombre de tables: {len(tables)}\")\n",
    "            \n",
    "            conn.close()\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur de connexion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ex√©cuter le test\n",
    "test_connection()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3Ô∏è‚É£ Extraction des Tables MySQL\n",
    "\n",
    "# %% Fonction d'extraction\n",
    "def extract_mysql_table(table_name, conn):\n",
    "    \"\"\"Extraire une table MySQL vers DataFrame\"\"\"\n",
    "    try:\n",
    "        print(f\"üìä Extraction: {table_name}...\", end=\" \")\n",
    "        \n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        \n",
    "        # Sauvegarder en CSV\n",
    "        filename = f\"data/extracted/{table_name.replace('table_', '')}.csv\"\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"‚úÖ {len(df)} lignes | {len(df.columns)} colonnes\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {e}\")\n",
    "        return None\n",
    "\n",
    "# %% Extraction de toutes les tables\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ EXTRACTION DES TABLES MySQL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Se connecter\n",
    "conn = mysql.connector.connect(**MYSQL_CONFIG)\n",
    "\n",
    "# Liste des tables √† extraire\n",
    "tables_to_extract = [\n",
    "    'table_sales',\n",
    "    'table_products',\n",
    "    'table_reviews',\n",
    "    'table_customers',\n",
    "    'table_stores',\n",
    "    'table_cities',\n",
    "    'table_categories',\n",
    "    'table_subcategories'\n",
    "]\n",
    "\n",
    "# Dictionnaire pour stocker les DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Extraire chaque table\n",
    "for table in tables_to_extract:\n",
    "    df = extract_mysql_table(table, conn)\n",
    "    if df is not None:\n",
    "        # Enlever le pr√©fixe \"table_\" pour le nom\n",
    "        clean_name = table.replace('table_', '')\n",
    "        dataframes[clean_name] = df\n",
    "\n",
    "# Fermer la connexion\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n‚úÖ Extraction MySQL termin√©e!\")\n",
    "print(f\"üì¶ {len(dataframes)} tables extraites\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4Ô∏è‚É£ Aper√ßu des Donn√©es Extraites\n",
    "\n",
    "# %% Afficher un aper√ßu\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã APER√áU DES DONN√âES EXTRAITES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\nüìä Table: {name}\")\n",
    "    print(f\"   Dimensions: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "    print(f\"   Colonnes: {', '.join(df.columns.tolist()[:5])}...\")\n",
    "    print(f\"   Aper√ßu:\")\n",
    "    print(df.head(3))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5Ô∏è‚É£ Statistiques des Ventes\n",
    "\n",
    "# %% Analyse rapide des ventes\n",
    "df_sales = dataframes['sales']\n",
    "\n",
    "print(\"\\nüìä STATISTIQUES DES VENTES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre total de ventes: {len(df_sales):,}\")\n",
    "print(f\"Revenu total: {df_sales['Total_Revenue'].sum():,.2f} DZD\")\n",
    "print(f\"Revenu moyen par vente: {df_sales['Total_Revenue'].mean():,.2f} DZD\")\n",
    "print(f\"P√©riode: {df_sales['Date'].min()} ‚Üí {df_sales['Date'].max()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6Ô∏è‚É£ Web Scraping - Prix Concurrents\n",
    "\n",
    "# %% Import du module de scraping\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üï∑Ô∏è  WEB SCRAPING - PRIX CONCURRENTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Ajouter le r√©pertoire scripts au path pour l'import\n",
    "sys.path.insert(0, 'scripts')\n",
    "\n",
    "try:\n",
    "    from scrape_competitors import scrape_with_fallback\n",
    "    \n",
    "    # Ex√©cuter le scraping\n",
    "    df_competitor = scrape_with_fallback()\n",
    "    \n",
    "    if df_competitor is not None:\n",
    "        print(f\"\\n‚úÖ Scraping termin√©: {len(df_competitor)} produits extraits\")\n",
    "        print(f\"üíæ Fichier sauvegard√©: data/extracted/competitor_prices.csv\")\n",
    "        \n",
    "        # Afficher un aper√ßu\n",
    "        print(\"\\nüìã Aper√ßu des prix concurrents:\")\n",
    "        print(df_competitor.head(10))\n",
    "        \n",
    "        # Ajouter au dictionnaire\n",
    "        dataframes['competitor_prices'] = df_competitor\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune donn√©e de concurrent r√©cup√©r√©e\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du scraping: {e}\")\n",
    "    print(\"üìù Le module de scraping doit √™tre disponible dans scripts/scrape_competitors.py\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7Ô∏è‚É£ Extraction des Factures Legacy (OCR - BONUS)\n",
    "\n",
    "# %% OCR Processing\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÑ EXTRACTION DES FACTURES LEGACY (OCR - BONUS)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Check if invoice images exist\n",
    "invoice_dir = 'data/legacy_invoices'\n",
    "has_invoices = os.path.exists(invoice_dir) and len([f for f in os.listdir(invoice_dir) \n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) > 0\n",
    "\n",
    "if has_invoices:\n",
    "    print(\"üìÅ Factures d√©tect√©es, lancement de l'OCR...\")\n",
    "    \n",
    "    try:\n",
    "        from extract_legacy_invoices import InvoiceOCRProcessor\n",
    "        \n",
    "        # Initialize and run OCR processor\n",
    "        processor = InvoiceOCRProcessor(invoice_dir)\n",
    "        df_legacy = processor.process_and_save()\n",
    "        \n",
    "        if df_legacy is not None and len(df_legacy) > 0:\n",
    "            print(f\"\\n‚úÖ OCR termin√©: {len(df_legacy)} factures trait√©es\")\n",
    "            print(f\"üíæ Fichier sauvegard√©: data/extracted/legacy_sales.csv\")\n",
    "            \n",
    "            # Display preview\n",
    "            print(\"\\nüìã Aper√ßu des ventes legacy:\")\n",
    "            print(df_legacy.head())\n",
    "            \n",
    "            # Add to dataframes dictionary\n",
    "            dataframes['legacy_sales'] = df_legacy\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Aucune donn√©e extraite par OCR\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è Module OCR non trouv√© (scripts/extract_legacy_invoices.py)\")\n",
    "        print(\"   Cette √©tape est optionnelle (BONUS)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur OCR: {e}\")\n",
    "        print(\"   Utilisation de donn√©es manuelles √† la place...\")\n",
    "        \n",
    "        try:\n",
    "            from extract_legacy_invoices import create_manual_data\n",
    "            df_legacy = create_manual_data()\n",
    "            dataframes['legacy_sales'] = df_legacy\n",
    "            print(\"‚úÖ Donn√©es manuelles cr√©√©es\")\n",
    "        except:\n",
    "            print(\"   Passage de cette √©tape\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Aucune facture trouv√©e dans data/legacy_invoices/\")\n",
    "    print(\"   Cette √©tape est optionnelle (BONUS)\")\n",
    "    print(\"   Pour activer: placez les images .jpg dans data/legacy_invoices/\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8Ô∏è‚É£ Validation des Donn√©es Extraites\n",
    "\n",
    "# %% V√©rifications de qualit√©\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ VALIDATION DES DONN√âES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    # V√©rifier les valeurs manquantes\n",
    "    missing = df.isnull().sum().sum()\n",
    "    missing_pct = (missing / (df.shape[0] * df.shape[1])) * 100\n",
    "    \n",
    "    # V√©rifier les doublons\n",
    "    duplicates = df.duplicated().sum()\n",
    "    \n",
    "    validation_results.append({\n",
    "        'Table': name,\n",
    "        'Lignes': len(df),\n",
    "        'Colonnes': len(df.columns),\n",
    "        'Valeurs_Manquantes': missing,\n",
    "        'Pct_Manquant': f\"{missing_pct:.2f}%\",\n",
    "        'Doublons': duplicates,\n",
    "        'Statut': '‚úÖ' if missing_pct < 5 and duplicates < 10 else '‚ö†Ô∏è'\n",
    "    })\n",
    "\n",
    "df_validation = pd.DataFrame(validation_results)\n",
    "print(df_validation.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9Ô∏è‚É£ Export Summary Report\n",
    "\n",
    "# %% Generate extraction summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä G√âN√âRATION DU RAPPORT D'EXTRACTION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary = {\n",
    "    'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'total_tables': len(dataframes),\n",
    "    'total_records': sum(len(df) for df in dataframes.values()),\n",
    "    'files_created': []\n",
    "}\n",
    "\n",
    "# List all created files with sizes\n",
    "for file in sorted(os.listdir('data/extracted')):\n",
    "    file_path = f\"data/extracted/{file}\"\n",
    "    file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "    summary['files_created'].append({\n",
    "        'filename': file,\n",
    "        'size_kb': round(file_size, 2),\n",
    "        'records': len(pd.read_csv(file_path))\n",
    "    })\n",
    "\n",
    "# Save summary to JSON\n",
    "import json\n",
    "with open('data/extracted/extraction_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Rapport d'extraction sauvegard√©: extraction_summary.json\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üîü R√©sum√© de l'Extraction\n",
    "\n",
    "# %% R√©sum√© final\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä R√âSUM√â DE L'EXTRACTION (MEMBRE 1)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ T√ÇCHES COMPL√âT√âES:\")\n",
    "print(\"   1. ‚úÖ Connexion MySQL √©tablie et test√©e\")\n",
    "print(f\"   2. ‚úÖ {len([k for k in dataframes.keys() if k not in ['competitor_prices', 'legacy_sales']])} tables extraites de l'ERP\")\n",
    "print(\"   3. ‚úÖ Web scraping des prix concurrents effectu√©\")\n",
    "\n",
    "if 'legacy_sales' in dataframes:\n",
    "    print(\"   4. ‚úÖ Extraction OCR des factures legacy (BONUS)\")\n",
    "else:\n",
    "    print(\"   4. ‚è≠Ô∏è  Extraction OCR non effectu√©e (optionnel)\")\n",
    "\n",
    "print(\"   5. ‚úÖ Toutes les donn√©es sauvegard√©es en CSV\")\n",
    "print(\"   6. ‚úÖ Validation de la qualit√© des donn√©es effectu√©e\")\n",
    "\n",
    "print(\"\\nüì¶ FICHIERS CR√â√âS:\")\n",
    "for file_info in summary['files_created']:\n",
    "    print(f\"   ‚Ä¢ {file_info['filename']:<30} ({file_info['size_kb']:>8.1f} KB) - {file_info['records']:>6,} lignes\")\n",
    "\n",
    "print(f\"\\nüìä STATISTIQUES GLOBALES:\")\n",
    "print(f\"   ‚Ä¢ Total de lignes extraites: {summary['total_records']:,}\")\n",
    "print(f\"   ‚Ä¢ Nombre de fichiers: {len(summary['files_created'])}\")\n",
    "print(f\"   ‚Ä¢ Date d'extraction: {summary['extraction_date']}\")\n",
    "\n",
    "print(\"\\nüöÄ PROCHAINE √âTAPE:\")\n",
    "print(\"   ‚Üí Membre 2 peut maintenant transformer ces donn√©es\")\n",
    "print(\"   ‚Üí Fichiers disponibles dans: data/extracted/\")\n",
    "print(\"   ‚Üí Rapport disponible dans: data/extracted/extraction_summary.json\")\n",
    "\n",
    "print(\"\\nüí° NOTES POUR L'√âQUIPE:\")\n",
    "print(\"   ‚Ä¢ Les donn√©es ERP couvrent la p√©riode 2023-2025\")\n",
    "print(\"   ‚Ä¢ Les prix concurrents sont √† jour √† la date d'extraction\")\n",
    "if 'legacy_sales' in dataframes:\n",
    "    print(\"   ‚Ä¢ Les factures legacy (2022) ont √©t√© num√©ris√©es (BONUS)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ EXTRACTION TERMIN√âE AVEC SUCC√àS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìù Notes de D√©veloppement\n",
    "# \n",
    "# ### Structure des fichiers cr√©√©s:\n",
    "# - `sales.csv`: Transactions de vente (OLTP)\n",
    "# - `products.csv`: Catalogue produits\n",
    "# - `customers.csv`: Profils clients\n",
    "# - `stores.csv`: Magasins\n",
    "# - `cities.csv`: G√©ographie\n",
    "# - `categories.csv` & `subcategories.csv`: Hi√©rarchie produits\n",
    "# - `reviews.csv`: Avis clients (pour sentiment analysis)\n",
    "# - `competitor_prices.csv`: Prix concurrents (web scraping)\n",
    "# - `legacy_sales.csv`: Ventes 2022 (OCR - optionnel)\n",
    "# \n",
    "# ### Prochaines √©tapes (Membre 2):\n",
    "# - Charger ces CSV\n",
    "# - Appliquer les transformations (nettoyage, enrichissement)\n",
    "# - Calculer Net_Profit avec les fichiers Excel\n",
    "# - Effectuer l'analyse de sentiment (VADER)\n",
    "# - Pr√©parer les donn√©es pour le Data Warehouse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
