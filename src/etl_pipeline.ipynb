{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a13b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Biblioth√®ques import√©es avec succ√®s\n",
      "üìÖ Date d'ex√©cution: 2025-12-29 20:46:06\n",
      "üìã Configuration charg√©e\n",
      "   Serveur: boughida.com\n",
      "   Base de donn√©es: techstore_erp\n",
      "‚úÖ Connexion MySQL r√©ussie!\n",
      "   Base de donn√©es active: techstore_erp\n",
      "   Nombre de tables: 8\n",
      "\n",
      "============================================================\n",
      "üöÄ EXTRACTION DES TABLES MySQL\n",
      "============================================================\n",
      "\n",
      "üìä Extraction: table_sales... ‚úÖ 25000 lignes | 7 colonnes\n",
      "üìä Extraction: table_products... ‚úÖ 38 lignes | 5 colonnes\n",
      "üìä Extraction: table_reviews... ‚úÖ 3000 lignes | 5 colonnes\n",
      "üìä Extraction: table_customers... ‚úÖ 1200 lignes | 3 colonnes\n",
      "üìä Extraction: table_stores... ‚úÖ 12 lignes | 3 colonnes\n",
      "üìä Extraction: table_cities... ‚úÖ 12 lignes | 3 colonnes\n",
      "üìä Extraction: table_categories... ‚úÖ 5 lignes | 2 colonnes\n",
      "üìä Extraction: table_subcategories... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 20:46:19,506 - INFO - ============================================================\n",
      "2025-12-29 20:46:19,507 - INFO - Starting web scraping process\n",
      "2025-12-29 20:46:19,508 - INFO - ============================================================\n",
      "2025-12-29 20:46:19,509 - INFO - Fetching page: https://boughida.com/competitor/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 15 lignes | 3 colonnes\n",
      "\n",
      "‚úÖ Extraction MySQL termin√©e!\n",
      "üì¶ 8 tables extraites\n",
      "\n",
      "============================================================\n",
      "üìã APER√áU DES DONN√âES EXTRAITES\n",
      "============================================================\n",
      "\n",
      "\n",
      "üìä Table: sales\n",
      "   Dimensions: 25000 lignes √ó 7 colonnes\n",
      "   Colonnes: Trans_ID, Date, Store_ID, Product_ID, Customer_ID...\n",
      "   Aper√ßu:\n",
      "   Trans_ID                Date  Store_ID Product_ID Customer_ID  Quantity  \\\n",
      "0         1 2024-07-02 17:15:00         3       P125       C0200         2   \n",
      "1         2 2023-07-01 13:52:00        11       P136       C0883         1   \n",
      "2         3 2025-01-05 18:56:00         7       P106       C0669         1   \n",
      "\n",
      "   Total_Revenue  \n",
      "0         9000.0  \n",
      "1         2500.0  \n",
      "2       320000.0  \n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Table: products\n",
      "   Dimensions: 38 lignes √ó 5 colonnes\n",
      "   Colonnes: Product_ID, Product_Name, SubCat_ID, Unit_Price, Unit_Cost...\n",
      "   Aper√ßu:\n",
      "  Product_ID    Product_Name  SubCat_ID  Unit_Price  Unit_Cost\n",
      "0       P100    HP Victus 15          1    125000.0    87901.0\n",
      "1       P101     Dell XPS 13          1    260000.0   167880.0\n",
      "2       P102  MacBook Air M2          1    195000.0   141052.0\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Table: reviews\n",
      "   Dimensions: 3000 lignes √ó 5 colonnes\n",
      "   Colonnes: Review_ID, Product_ID, Customer_ID, Rating, Review_Text...\n",
      "   Aper√ßu:\n",
      "   Review_ID Product_ID Customer_ID  Rating  \\\n",
      "0          1       P127       C1149       3   \n",
      "1          2       P103       C0116       5   \n",
      "2          3       P102       C0238       4   \n",
      "\n",
      "                                    Review_Text  \n",
      "0        Average, expected better battery life.  \n",
      "1        Excellent product, highly recommended!  \n",
      "2  Good, but shipping was a bit slow to Guelma.  \n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Table: customers\n",
      "   Dimensions: 1200 lignes √ó 3 colonnes\n",
      "   Colonnes: Customer_ID, Full_Name, City_ID...\n",
      "   Aper√ßu:\n",
      "  Customer_ID     Full_Name  City_ID\n",
      "0       C0001   Fares Mekki        9\n",
      "1       C0002   Zineb Oukil       10\n",
      "2       C0003  Amel Rahmani        2\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Table: stores\n",
      "   Dimensions: 12 lignes √ó 3 colonnes\n",
      "   Colonnes: Store_ID, Store_Name, City_ID...\n",
      "   Aper√ßu:\n",
      "   Store_ID                   Store_Name  City_ID\n",
      "0         1       TechStore Alger Centre        1\n",
      "1         2         TechStore Oran Bahia        2\n",
      "2         3  TechStore Constantine Cirta        3\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Table: cities\n",
      "   Dimensions: 12 lignes √ó 3 colonnes\n",
      "   Colonnes: City_ID, City_Name, Region...\n",
      "   Aper√ßu:\n",
      "   City_ID    City_Name Region\n",
      "0        1        Alger  North\n",
      "1        2         Oran   West\n",
      "2        3  Constantine   East\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Table: categories\n",
      "   Dimensions: 5 lignes √ó 2 colonnes\n",
      "   Colonnes: Category_ID, Category_Name...\n",
      "   Aper√ßu:\n",
      "   Category_ID Category_Name\n",
      "0            1     Computers\n",
      "1            2   Smartphones\n",
      "2            3         Audio\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Table: subcategories\n",
      "   Dimensions: 15 lignes √ó 3 colonnes\n",
      "   Colonnes: SubCat_ID, SubCat_Name, Category_ID...\n",
      "   Aper√ßu:\n",
      "   SubCat_ID SubCat_Name  Category_ID\n",
      "0          1     Laptops            1\n",
      "1          2    Desktops            1\n",
      "2          3    Monitors            1\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä STATISTIQUES DES VENTES\n",
      "============================================================\n",
      "Nombre total de ventes: 25,000\n",
      "Revenu total: 859,661,700.00 DZD\n",
      "Revenu moyen par vente: 34,386.47 DZD\n",
      "P√©riode: 2023-01-01 09:43:00 ‚Üí 2025-12-30 20:58:00\n",
      "\n",
      "============================================================\n",
      "üï∑Ô∏è  WEB SCRAPING - PRIX CONCURRENTS\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 20:46:21,583 - INFO - Page successfully retrieved\n",
      "2025-12-29 20:46:21,587 - INFO - Found additional pages: 2\n",
      "2025-12-29 20:46:21,590 - INFO - \n",
      "Page 1/3: https://boughida.com/competitor/\n",
      "2025-12-29 20:46:21,593 - INFO - ------------------------------------------------------------\n",
      "2025-12-29 20:46:21,595 - INFO - Fetching page: https://boughida.com/competitor/\n",
      "2025-12-29 20:46:22,796 - INFO - Page successfully retrieved\n",
      "2025-12-29 20:46:22,800 - INFO - Found 13 potential product containers\n",
      "2025-12-29 20:46:22,804 - INFO - Extracted: Samsung S23 Ultra: 174800.0 DZD\n",
      "2025-12-29 20:46:22,806 - INFO - Extracted: HP LaserJet Pro: 46000.0 DZD\n",
      "2025-12-29 20:46:22,807 - INFO - Extracted: Dell 24 Monitor: 24200.0 DZD\n",
      "2025-12-29 20:46:22,808 - INFO - Extracted: Canon i-Sensys: 39000.0 DZD\n",
      "2025-12-29 20:46:22,808 - INFO - Extracted: Epson EcoTank: 27700.0 DZD\n",
      "2025-12-29 20:46:22,809 - INFO - Extracted: Nikon D3500: 69200.0 DZD\n",
      "2025-12-29 20:46:22,811 - INFO - Extracted: Xiaomi Redmi Note 12: 36800.0 DZD\n",
      "2025-12-29 20:46:22,812 - INFO - Extracted: HP Pavilion Desktop: 83000.0 DZD\n",
      "2025-12-29 20:46:22,813 - INFO - Extracted: Redmi Buds 4: 5300.0 DZD\n",
      "2025-12-29 20:46:22,814 - INFO - Extracted: DJI Mini 3: 126900.0 DZD\n",
      "2025-12-29 20:46:22,815 - INFO - Extracted: Sony SRS-XB13: 11100.0 DZD\n",
      "2025-12-29 20:46:22,817 - INFO - Extracted: ASUS ROG STRIX: 290600.0 DZD\n",
      "2025-12-29 20:46:22,819 - INFO - Extracted: LG UltraGear: 41700.0 DZD\n",
      "2025-12-29 20:46:24,821 - INFO - \n",
      "Page 2/3: https://boughida.com/competitor/competitor_page_2.html\n",
      "2025-12-29 20:46:24,823 - INFO - ------------------------------------------------------------\n",
      "2025-12-29 20:46:24,827 - INFO - Fetching page: https://boughida.com/competitor/competitor_page_2.html\n",
      "2025-12-29 20:46:25,706 - INFO - Page successfully retrieved\n",
      "2025-12-29 20:46:25,710 - INFO - Found 13 potential product containers\n",
      "2025-12-29 20:46:25,713 - INFO - Extracted: IPHONE CABLE: 3200.0 DZD\n",
      "2025-12-29 20:46:25,714 - INFO - Extracted: Lenovo ThinkPad: 94600.0 DZD\n",
      "2025-12-29 20:46:25,715 - INFO - Extracted: AirPods Pro: 47400.0 DZD\n",
      "2025-12-29 20:46:25,715 - INFO - Extracted: Phone Case Silicon: 1800.0 DZD\n",
      "2025-12-29 20:46:25,716 - INFO - Extracted: Sony WH-1000XM5: 65400.0 DZD\n",
      "2025-12-29 20:46:25,716 - INFO - Extracted: iPhone 13: 136900.0 DZD\n",
      "2025-12-29 20:46:25,717 - INFO - Extracted: Canon 445 Black: 2600.0 DZD\n",
      "2025-12-29 20:46:25,718 - INFO - Extracted: DJI Mavic 3: 350400.0 DZD\n",
      "2025-12-29 20:46:25,718 - INFO - Extracted: JBL Flip 6: 23500.0 DZD\n",
      "2025-12-29 20:46:25,719 - INFO - Extracted: HP VICTUS 15: 119700.0 DZD\n",
      "2025-12-29 20:46:25,720 - INFO - Extracted: HP 650 Black: 2900.0 DZD\n",
      "2025-12-29 20:46:25,721 - INFO - Extracted: Oppo Reno 8: 60200.0 DZD\n",
      "2025-12-29 20:46:25,721 - INFO - Extracted: SAMSUNG CHARGER 25W: 4200.0 DZD\n",
      "2025-12-29 20:46:27,722 - INFO - \n",
      "Page 3/3: https://boughida.com/competitor/competitor_page_3.html\n",
      "2025-12-29 20:46:27,725 - INFO - ------------------------------------------------------------\n",
      "2025-12-29 20:46:27,727 - INFO - Fetching page: https://boughida.com/competitor/competitor_page_3.html\n",
      "2025-12-29 20:46:28,734 - INFO - Page successfully retrieved\n",
      "2025-12-29 20:46:28,740 - INFO - Found 12 potential product containers\n",
      "2025-12-29 20:46:28,741 - INFO - Extracted: MacBook Air M2: 190500.0 DZD\n",
      "2025-12-29 20:46:28,742 - INFO - Extracted: Canon Pixma: 11600.0 DZD\n",
      "2025-12-29 20:46:28,743 - INFO - Extracted: Canon EOS 4000D: 60200.0 DZD\n",
      "2025-12-29 20:46:28,744 - INFO - Extracted: JBL Tune 510BT: 11200.0 DZD\n",
      "2025-12-29 20:46:28,745 - INFO - Extracted: Screen Protector: 930.0 DZD\n",
      "2025-12-29 20:46:28,746 - INFO - Extracted: Custom Gaming PC: 300000.0 DZD\n",
      "2025-12-29 20:46:28,747 - INFO - Extracted: Samsung Odyssey G5: 46700.0 DZD\n",
      "2025-12-29 20:46:28,748 - INFO - Extracted: Realme GT3: 71700.0 DZD\n",
      "2025-12-29 20:46:28,749 - INFO - Extracted: iPhone 14 Pro: 212700.0 DZD\n",
      "2025-12-29 20:46:28,751 - INFO - Extracted: IPHONE 15 PRO MAX: 281500.0 DZD\n",
      "2025-12-29 20:46:28,753 - INFO - Extracted: Dell XPS 13 5G: 242700.0 DZD\n",
      "2025-12-29 20:46:28,754 - INFO - Extracted: Dell OptiPlex: 64400.0 DZD\n",
      "2025-12-29 20:46:28,755 - INFO - ============================================================\n",
      "2025-12-29 20:46:28,756 - INFO - Scraping completed: 38 total products\n",
      "2025-12-29 20:46:28,757 - INFO - ============================================================\n",
      "2025-12-29 20:46:28,762 - INFO - \n",
      "Data saved to: data/extracted/competitor_prices.csv\n",
      "2025-12-29 20:46:28,763 - INFO - Statistics:\n",
      "2025-12-29 20:46:28,764 - INFO -   Total products: 38\n",
      "2025-12-29 20:46:28,768 - INFO -   Average price: 89032.37 DZD\n",
      "2025-12-29 20:46:28,771 - INFO -   Price range: 930 - 350400 DZD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Scraping termin√©: 38 produits extraits\n",
      "üíæ Fichier sauvegard√©: data/extracted/competitor_prices.csv\n",
      "\n",
      "üìã Aper√ßu des prix concurrents:\n",
      "  Competitor_Product_Name  Competitor_Price Product_Reference Currency\n",
      "0       Samsung S23 Ultra          174800.0       Ref: P-5333      DZD\n",
      "1         HP LaserJet Pro           46000.0       Ref: P-7201      DZD\n",
      "2         Dell 24 Monitor           24200.0       Ref: P-1750      DZD\n",
      "3          Canon i-Sensys           39000.0       Ref: P-4814      DZD\n",
      "4           Epson EcoTank           27700.0       Ref: P-6977      DZD\n",
      "5             Nikon D3500           69200.0       Ref: P-2169      DZD\n",
      "6    Xiaomi Redmi Note 12           36800.0       Ref: P-3677      DZD\n",
      "7     HP Pavilion Desktop           83000.0       Ref: P-4598      DZD\n",
      "8            Redmi Buds 4            5300.0       Ref: P-4752      DZD\n",
      "9              DJI Mini 3          126900.0       Ref: P-2084      DZD\n",
      "\n",
      "============================================================\n",
      "üìÑ EXTRACTION DES FACTURES LEGACY (OCR - BONUS)\n",
      "============================================================\n",
      "\n",
      "üìÅ Factures d√©tect√©es, lancement de l'OCR...\n",
      "‚ö†Ô∏è Module OCR non trouv√© (scripts/extract_legacy_invoices.py)\n",
      "   Cette √©tape est optionnelle (BONUS)\n",
      "\n",
      "============================================================\n",
      "‚úÖ VALIDATION DES DONN√âES\n",
      "============================================================\n",
      "\n",
      "            Table  Lignes  Colonnes  Valeurs_Manquantes Pct_Manquant  Doublons Statut\n",
      "            sales   25000         7                   0        0.00%         0      ‚úÖ\n",
      "         products      38         5                   0        0.00%         0      ‚úÖ\n",
      "          reviews    3000         5                   0        0.00%         0      ‚úÖ\n",
      "        customers    1200         3                   0        0.00%         0      ‚úÖ\n",
      "           stores      12         3                   0        0.00%         0      ‚úÖ\n",
      "           cities      12         3                   0        0.00%         0      ‚úÖ\n",
      "       categories       5         2                   0        0.00%         0      ‚úÖ\n",
      "    subcategories      15         3                   0        0.00%         0      ‚úÖ\n",
      "competitor_prices      38         4                   0        0.00%         0      ‚úÖ\n",
      "\n",
      "============================================================\n",
      "üìä G√âN√âRATION DU RAPPORT D'EXTRACTION\n",
      "============================================================\n",
      "\n",
      "‚úÖ Rapport d'extraction sauvegard√©: extraction_summary.json\n",
      "\n",
      "======================================================================\n",
      "üìä R√âSUM√â DE L'EXTRACTION (MEMBRE 1)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ T√ÇCHES COMPL√âT√âES:\n",
      "   1. ‚úÖ Connexion MySQL √©tablie et test√©e\n",
      "   2. ‚úÖ 8 tables extraites de l'ERP\n",
      "   3. ‚úÖ Web scraping des prix concurrents effectu√©\n",
      "   4. ‚è≠Ô∏è  Extraction OCR non effectu√©e (optionnel)\n",
      "   5. ‚úÖ Toutes les donn√©es sauvegard√©es en CSV\n",
      "   6. ‚úÖ Validation de la qualit√© des donn√©es effectu√©e\n",
      "\n",
      "üì¶ FICHIERS CR√â√âS:\n",
      "   ‚Ä¢ categories.csv                 (     0.1 KB) -      5 lignes\n",
      "   ‚Ä¢ cities.csv                     (     0.2 KB) -     12 lignes\n",
      "   ‚Ä¢ competitor_prices.csv          (     1.6 KB) -     38 lignes\n",
      "   ‚Ä¢ customers.csv                  (    26.9 KB) -  1,200 lignes\n",
      "   ‚Ä¢ extraction_summary.csv         (     0.3 KB) -      8 lignes\n",
      "   ‚Ä¢ extraction_summary.json        (     1.3 KB) -     66 lignes\n",
      "   ‚Ä¢ legacy_sales.csv               (     0.5 KB) -      5 lignes\n",
      "   ‚Ä¢ products.csv                   (     1.5 KB) -     38 lignes\n",
      "   ‚Ä¢ reviews.csv                    (   179.5 KB) -  3,000 lignes\n",
      "   ‚Ä¢ sales.csv                      (  1199.7 KB) - 25,000 lignes\n",
      "   ‚Ä¢ stores.csv                     (     0.4 KB) -     12 lignes\n",
      "   ‚Ä¢ subcategories.csv              (     0.3 KB) -     15 lignes\n",
      "\n",
      "üìä STATISTIQUES GLOBALES:\n",
      "   ‚Ä¢ Total de lignes extraites: 29,320\n",
      "   ‚Ä¢ Nombre de fichiers: 12\n",
      "   ‚Ä¢ Date d'extraction: 2025-12-29 20:46:28\n",
      "\n",
      "üöÄ PROCHAINE √âTAPE:\n",
      "   ‚Üí Membre 2 peut maintenant transformer ces donn√©es\n",
      "   ‚Üí Fichiers disponibles dans: data/extracted/\n",
      "   ‚Üí Rapport disponible dans: data/extracted/extraction_summary.json\n",
      "\n",
      "üí° NOTES POUR L'√âQUIPE:\n",
      "   ‚Ä¢ Les donn√©es ERP couvrent la p√©riode 2023-2025\n",
      "   ‚Ä¢ Les prix concurrents sont √† jour √† la date d'extraction\n",
      "\n",
      "======================================================================\n",
      "‚úÖ EXTRACTION TERMIN√âE AVEC SUCC√àS\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# PROJET BUSINESS INTELLIGENCE - TECHSTORE\n",
    "# ETL PIPELINE - PARTIE MEMBRE 1 : DATA EXTRACTION\n",
    "# ====================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # üìä Extraction des Donn√©es (Membre 1)\n",
    "# \n",
    "# Ce notebook contient la partie extraction du pipeline ETL.\n",
    "# **Responsable :** Membre 1 - Data Extraction Engineer\n",
    "# \n",
    "# ## Objectifs :\n",
    "# 1. ‚úÖ Extraire les donn√©es de MySQL (ERP)\n",
    "# 2. ‚úÖ Scraper les prix des concurrents\n",
    "# 3. ‚úÖ Extraire les factures legacy (OCR - BONUS)\n",
    "# 4. ‚úÖ Valider la qualit√© des donn√©es extraites\n",
    "\n",
    "# %% Imports pour tout le pipeline ETL\n",
    "# Installer les d√©pendances manquantes (ex√©cuter uniquement dans le notebook)\n",
    "\n",
    "\n",
    "# === Imports de base ===\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Partie 1 : Extraction (Membre 1) ===\n",
    "import mysql.connector\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# === Partie 2 : Transformations (Membre 2 - Toi) ===\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "from fuzzywuzzy import process  # Pour le matching des prix concurrents\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es avec succ√®s\")\n",
    "print(f\"üìÖ Date d'ex√©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1Ô∏è‚É£ Configuration de la Connexion MySQL\n",
    "\n",
    "# %% Configuration\n",
    "MYSQL_CONFIG = {\n",
    "    'host': 'boughida.com',\n",
    "    'database': 'techstore_erp',\n",
    "    'user': 'student_user_4ing',\n",
    "    'password': 'bi_guelma_2025'\n",
    "}\n",
    "\n",
    "# Cr√©er les r√©pertoires n√©cessaires\n",
    "os.makedirs('data/extracted', exist_ok=True)\n",
    "os.makedirs('data/legacy_invoices', exist_ok=True)\n",
    "\n",
    "print(\"üìã Configuration charg√©e\")\n",
    "print(f\"   Serveur: {MYSQL_CONFIG['host']}\")\n",
    "print(f\"   Base de donn√©es: {MYSQL_CONFIG['database']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2Ô∏è‚É£ Connexion et Test\n",
    "\n",
    "# %% Test de connexion\n",
    "def test_connection():\n",
    "    \"\"\"Tester la connexion √† MySQL\"\"\"\n",
    "    try:\n",
    "        conn = mysql.connector.connect(**MYSQL_CONFIG)\n",
    "        if conn.is_connected():\n",
    "            print(\"‚úÖ Connexion MySQL r√©ussie!\")\n",
    "            \n",
    "            # Tester une requ√™te simple\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT DATABASE()\")\n",
    "            db_name = cursor.fetchone()[0]\n",
    "            print(f\"   Base de donn√©es active: {db_name}\")\n",
    "            \n",
    "            # Lister les tables disponibles\n",
    "            cursor.execute(\"SHOW TABLES\")\n",
    "            tables = cursor.fetchall()\n",
    "            print(f\"   Nombre de tables: {len(tables)}\")\n",
    "            \n",
    "            conn.close()\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur de connexion: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ex√©cuter le test\n",
    "test_connection()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3Ô∏è‚É£ Extraction des Tables MySQL\n",
    "\n",
    "# %% Fonction d'extraction\n",
    "def extract_mysql_table(table_name, conn):\n",
    "    \"\"\"Extraire une table MySQL vers DataFrame\"\"\"\n",
    "    try:\n",
    "        print(f\"üìä Extraction: {table_name}...\", end=\" \")\n",
    "        \n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        \n",
    "        # Sauvegarder en CSV\n",
    "        filename = f\"data/extracted/{table_name.replace('table_', '')}.csv\"\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"‚úÖ {len(df)} lignes | {len(df.columns)} colonnes\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {e}\")\n",
    "        return None\n",
    "\n",
    "# %% Extraction de toutes les tables\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ EXTRACTION DES TABLES MySQL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Se connecter\n",
    "conn = mysql.connector.connect(**MYSQL_CONFIG)\n",
    "\n",
    "# Liste des tables √† extraire\n",
    "tables_to_extract = [\n",
    "    'table_sales',\n",
    "    'table_products',\n",
    "    'table_reviews',\n",
    "    'table_customers',\n",
    "    'table_stores',\n",
    "    'table_cities',\n",
    "    'table_categories',\n",
    "    'table_subcategories'\n",
    "]\n",
    "\n",
    "# Dictionnaire pour stocker les DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Extraire chaque table\n",
    "for table in tables_to_extract:\n",
    "    df = extract_mysql_table(table, conn)\n",
    "    if df is not None:\n",
    "        # Enlever le pr√©fixe \"table_\" pour le nom\n",
    "        clean_name = table.replace('table_', '')\n",
    "        dataframes[clean_name] = df\n",
    "\n",
    "# Fermer la connexion\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n‚úÖ Extraction MySQL termin√©e!\")\n",
    "print(f\"üì¶ {len(dataframes)} tables extraites\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4Ô∏è‚É£ Aper√ßu des Donn√©es Extraites\n",
    "\n",
    "# %% Afficher un aper√ßu\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã APER√áU DES DONN√âES EXTRAITES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"\\nüìä Table: {name}\")\n",
    "    print(f\"   Dimensions: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "    print(f\"   Colonnes: {', '.join(df.columns.tolist()[:5])}...\")\n",
    "    print(f\"   Aper√ßu:\")\n",
    "    print(df.head(3))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5Ô∏è‚É£ Statistiques des Ventes\n",
    "\n",
    "# %% Analyse rapide des ventes\n",
    "df_sales = dataframes['sales']\n",
    "\n",
    "print(\"\\nüìä STATISTIQUES DES VENTES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Nombre total de ventes: {len(df_sales):,}\")\n",
    "print(f\"Revenu total: {df_sales['Total_Revenue'].sum():,.2f} DZD\")\n",
    "print(f\"Revenu moyen par vente: {df_sales['Total_Revenue'].mean():,.2f} DZD\")\n",
    "print(f\"P√©riode: {df_sales['Date'].min()} ‚Üí {df_sales['Date'].max()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6Ô∏è‚É£ Web Scraping - Prix Concurrents\n",
    "\n",
    "# %% Import du module de scraping\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üï∑Ô∏è  WEB SCRAPING - PRIX CONCURRENTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Ajouter le r√©pertoire scripts au path pour l'import\n",
    "sys.path.insert(0, 'scripts')\n",
    "\n",
    "try:\n",
    "    from scrape_competitors import scrape_with_fallback\n",
    "    \n",
    "    # Ex√©cuter le scraping\n",
    "    df_competitor = scrape_with_fallback()\n",
    "    \n",
    "    if df_competitor is not None:\n",
    "        print(f\"\\n‚úÖ Scraping termin√©: {len(df_competitor)} produits extraits\")\n",
    "        print(f\"üíæ Fichier sauvegard√©: data/extracted/competitor_prices.csv\")\n",
    "        \n",
    "        # Afficher un aper√ßu\n",
    "        print(\"\\nüìã Aper√ßu des prix concurrents:\")\n",
    "        print(df_competitor.head(10))\n",
    "        \n",
    "        # Ajouter au dictionnaire\n",
    "        dataframes['competitor_prices'] = df_competitor\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune donn√©e de concurrent r√©cup√©r√©e\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du scraping: {e}\")\n",
    "    print(\"üìù Le module de scraping doit √™tre disponible dans scripts/scrape_competitors.py\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7Ô∏è‚É£ Extraction des Factures Legacy (OCR - BONUS)\n",
    "\n",
    "# %% OCR Processing\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÑ EXTRACTION DES FACTURES LEGACY (OCR - BONUS)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Check if invoice images exist\n",
    "invoice_dir = 'data/legacy_invoices'\n",
    "has_invoices = os.path.exists(invoice_dir) and len([f for f in os.listdir(invoice_dir) \n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) > 0\n",
    "\n",
    "if has_invoices:\n",
    "    print(\"üìÅ Factures d√©tect√©es, lancement de l'OCR...\")\n",
    "    \n",
    "    try:\n",
    "        from extract_legacy_invoices import InvoiceOCRProcessor\n",
    "        \n",
    "        # Initialize and run OCR processor\n",
    "        processor = InvoiceOCRProcessor(invoice_dir)\n",
    "        df_legacy = processor.process_and_save()\n",
    "        \n",
    "        if df_legacy is not None and len(df_legacy) > 0:\n",
    "            print(f\"\\n‚úÖ OCR termin√©: {len(df_legacy)} factures trait√©es\")\n",
    "            print(f\"üíæ Fichier sauvegard√©: data/extracted/legacy_sales.csv\")\n",
    "            \n",
    "            # Display preview\n",
    "            print(\"\\nüìã Aper√ßu des ventes legacy:\")\n",
    "            print(df_legacy.head())\n",
    "            \n",
    "            # Add to dataframes dictionary\n",
    "            dataframes['legacy_sales'] = df_legacy\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Aucune donn√©e extraite par OCR\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è Module OCR non trouv√© (scripts/extract_legacy_invoices.py)\")\n",
    "        print(\"   Cette √©tape est optionnelle (BONUS)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur OCR: {e}\")\n",
    "        print(\"   Utilisation de donn√©es manuelles √† la place...\")\n",
    "        \n",
    "        try:\n",
    "            from extract_legacy_invoices import create_manual_data\n",
    "            df_legacy = create_manual_data()\n",
    "            dataframes['legacy_sales'] = df_legacy\n",
    "            print(\"‚úÖ Donn√©es manuelles cr√©√©es\")\n",
    "        except:\n",
    "            print(\"   Passage de cette √©tape\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Aucune facture trouv√©e dans data/legacy_invoices/\")\n",
    "    print(\"   Cette √©tape est optionnelle (BONUS)\")\n",
    "    print(\"   Pour activer: placez les images .jpg dans data/legacy_invoices/\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8Ô∏è‚É£ Validation des Donn√©es Extraites\n",
    "\n",
    "# %% V√©rifications de qualit√©\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ VALIDATION DES DONN√âES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    # V√©rifier les valeurs manquantes\n",
    "    missing = df.isnull().sum().sum()\n",
    "    missing_pct = (missing / (df.shape[0] * df.shape[1])) * 100\n",
    "    \n",
    "    # V√©rifier les doublons\n",
    "    duplicates = df.duplicated().sum()\n",
    "    \n",
    "    validation_results.append({\n",
    "        'Table': name,\n",
    "        'Lignes': len(df),\n",
    "        'Colonnes': len(df.columns),\n",
    "        'Valeurs_Manquantes': missing,\n",
    "        'Pct_Manquant': f\"{missing_pct:.2f}%\",\n",
    "        'Doublons': duplicates,\n",
    "        'Statut': '‚úÖ' if missing_pct < 5 and duplicates < 10 else '‚ö†Ô∏è'\n",
    "    })\n",
    "\n",
    "df_validation = pd.DataFrame(validation_results)\n",
    "print(df_validation.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9Ô∏è‚É£ Export Summary Report\n",
    "\n",
    "# %% Generate extraction summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä G√âN√âRATION DU RAPPORT D'EXTRACTION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "summary = {\n",
    "    'extraction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'total_tables': len(dataframes),\n",
    "    'total_records': sum(len(df) for df in dataframes.values()),\n",
    "    'files_created': []\n",
    "}\n",
    "\n",
    "# List all created files with sizes\n",
    "for file in sorted(os.listdir('data/extracted')):\n",
    "    file_path = f\"data/extracted/{file}\"\n",
    "    file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "    summary['files_created'].append({\n",
    "        'filename': file,\n",
    "        'size_kb': round(file_size, 2),\n",
    "        'records': len(pd.read_csv(file_path))\n",
    "    })\n",
    "\n",
    "# Save summary to JSON\n",
    "import json\n",
    "with open('data/extracted/extraction_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Rapport d'extraction sauvegard√©: extraction_summary.json\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üîü R√©sum√© de l'Extraction\n",
    "\n",
    "# %% R√©sum√© final\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä R√âSUM√â DE L'EXTRACTION (MEMBRE 1)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ T√ÇCHES COMPL√âT√âES:\")\n",
    "print(\"   1. ‚úÖ Connexion MySQL √©tablie et test√©e\")\n",
    "print(f\"   2. ‚úÖ {len([k for k in dataframes.keys() if k not in ['competitor_prices', 'legacy_sales']])} tables extraites de l'ERP\")\n",
    "print(\"   3. ‚úÖ Web scraping des prix concurrents effectu√©\")\n",
    "\n",
    "if 'legacy_sales' in dataframes:\n",
    "    print(\"   4. ‚úÖ Extraction OCR des factures legacy (BONUS)\")\n",
    "else:\n",
    "    print(\"   4. ‚è≠Ô∏è  Extraction OCR non effectu√©e (optionnel)\")\n",
    "\n",
    "print(\"   5. ‚úÖ Toutes les donn√©es sauvegard√©es en CSV\")\n",
    "print(\"   6. ‚úÖ Validation de la qualit√© des donn√©es effectu√©e\")\n",
    "\n",
    "print(\"\\nüì¶ FICHIERS CR√â√âS:\")\n",
    "for file_info in summary['files_created']:\n",
    "    print(f\"   ‚Ä¢ {file_info['filename']:<30} ({file_info['size_kb']:>8.1f} KB) - {file_info['records']:>6,} lignes\")\n",
    "\n",
    "print(f\"\\nüìä STATISTIQUES GLOBALES:\")\n",
    "print(f\"   ‚Ä¢ Total de lignes extraites: {summary['total_records']:,}\")\n",
    "print(f\"   ‚Ä¢ Nombre de fichiers: {len(summary['files_created'])}\")\n",
    "print(f\"   ‚Ä¢ Date d'extraction: {summary['extraction_date']}\")\n",
    "\n",
    "print(\"\\nüöÄ PROCHAINE √âTAPE:\")\n",
    "print(\"   ‚Üí Membre 2 peut maintenant transformer ces donn√©es\")\n",
    "print(\"   ‚Üí Fichiers disponibles dans: data/extracted/\")\n",
    "print(\"   ‚Üí Rapport disponible dans: data/extracted/extraction_summary.json\")\n",
    "\n",
    "print(\"\\nüí° NOTES POUR L'√âQUIPE:\")\n",
    "print(\"   ‚Ä¢ Les donn√©es ERP couvrent la p√©riode 2023-2025\")\n",
    "print(\"   ‚Ä¢ Les prix concurrents sont √† jour √† la date d'extraction\")\n",
    "if 'legacy_sales' in dataframes:\n",
    "    print(\"   ‚Ä¢ Les factures legacy (2022) ont √©t√© num√©ris√©es (BONUS)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ EXTRACTION TERMIN√âE AVEC SUCC√àS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìù Notes de D√©veloppement\n",
    "# \n",
    "# ### Structure des fichiers cr√©√©s:\n",
    "# - `sales.csv`: Transactions de vente (OLTP)\n",
    "# - `products.csv`: Catalogue produits\n",
    "# - `customers.csv`: Profils clients\n",
    "# - `stores.csv`: Magasins\n",
    "# - `cities.csv`: G√©ographie\n",
    "# - `categories.csv` & `subcategories.csv`: Hi√©rarchie produits\n",
    "# - `reviews.csv`: Avis clients (pour sentiment analysis)\n",
    "# - `competitor_prices.csv`: Prix concurrents (web scraping)\n",
    "# - `legacy_sales.csv`: Ventes 2022 (OCR - optionnel)\n",
    "# \n",
    "# ### Prochaines √©tapes (Membre 2):\n",
    "# - Charger ces CSV\n",
    "# - Appliquer les transformations (nettoyage, enrichissement)\n",
    "# - Calculer Net_Profit avec les fichiers Excel\n",
    "# - Effectuer l'analyse de sentiment (VADER)\n",
    "# - Pr√©parer les donn√©es pour le Data Warehouse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
